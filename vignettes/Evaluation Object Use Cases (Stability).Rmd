---
title: "Evaluation Object Use Cases"
author: "Sanghyun Kim"
date: "`r Sys.Date()`"
output:
  html_document:
    fig_caption: yes
    number_sections: yes
    self_contained: yes
    theme: flatly
    toc: true
    toc_depth: 3
    toc_float: true
    code_folding: hide
---

```{r setup, include = FALSE}
library(knitr)
opts_chunk$set(echo = TRUE)
opts_chunk$set(message = FALSE, warning = FALSE)
```

```{r}
library(tidyverse)
library(R6)
library(PD16Sdata)
library(phyloseq)
library(microViz)
library(microbiome)
library(biomformat)
library(zeroSum)
library(CPOP)
library(NetCoMi)
library(glmnet)
library(viridis)
library(Biostrings)
library(tigger)
library(caret)
library(SimBenchData)
library(ExperimentHub)
library(Seurat)
library(limma)
library(kableExtra)
theme_set(theme_bw())
```

```{r}
sys.source("Evaluation Object Functions.R", knitr::knit_global())
```

# Microbiome Evaluation Framework {.tabset}

## evalTrio Objects

```{r}
# get_micro_data extracts preprocessed evalData and gsResult 
get_micro_data = function(phyloseq_obj, min_prev_val, trans) {
  if (class(phyloseq_obj) != "phyloseq" & class(phyloseq_obj) != "psExtra") {
    stop("phyloseq_obj must be a phyloseq class object!")
  }
  
  # data preprocessing
  data = phyloseq_obj %>% 
    subset_samples(!is.na(PD)) %>% 
    microViz::tax_filter(min_prevalence = min_prev_val) %>% 
    microViz::tax_transform(trans = trans)
    
  
  # get the otu table
  otu_tab = as(phyloseq::otu_table(data), "matrix")
  otu_tab = otu_tab[apply(otu_tab, 1, function(x) sd(x) != 0), ]

  # filter out samples with 0 variance of microbial taxa abundance
  sample = rownames(otu_tab)
  
  # get the gs result
  gs_result = data %>% 
    microViz::samdat_tbl() %>% 
    dplyr::filter(.sample_name %in% sample) %>% 
    dplyr::mutate(PD = dplyr::case_when(PD == "PD" ~ 1,
                                        PD == "HC" ~ 0)) %>% 
    dplyr::pull(PD)
    
  return(list(evalData = otu_tab,
              gsResult = gs_result))
}
```

```{r}
lubom0 = ps_filter(ps_list$Lubomski, t == "0")
lubom6 = ps_filter(ps_list$Lubomski, t == "6")
lubom12 = ps_filter(ps_list$Lubomski, t == "12")
aho = ps_list$Aho
jin = ps_list$Jin

micro_list = list(Lubomski0 = lubom0,
                  Lubomski6 = lubom6,
                  Lubomski12 = lubom12,
                  Aho = aho)
```

```{r}
# generate evalTrio objects for all the data and put them into a list
eval_trio_list = list()

for (i in 1:length(micro_list)) {
  # get evalData from phyloseq_obj
  otu_tab = get_micro_data(micro_list[[i]], min_prev_val = 0.05, trans = "compositional")[[1]]
  
  # get gsResult for both accuracy and stability evaluation tasks
  gs_result = get_micro_data(micro_list[[i]], min_prev_val = 0.05, trans = "compositional")[[2]]
  
  # create an evalTask object
  eval_task1 = evalTask_obj_generator(task_name = "Accuracy",
                                     gs_result = gs_result)
  eval_task2 = evalTask_obj_generator(task_name = "Stability",
                                     gs_result = gs_result)
  
  eval_task_list = list(eval_task1, eval_task2)
  
  # get the name of current microbiome data
  data_name = names(micro_list)[[i]]
  
  # create an evalTrio object
  eval_trio = evalTrio_obj_generator(eval_data = otu_tab,
                                     data_name = data_name,
                                     organism = "Human",
                                     research_area = "Microbiome",
                                     eval_task_list = eval_task_list)
  eval_trio_list[[data_name]] = eval_trio
}
```

## Model Construction {.tabset}

### CPOP

```{r, messasge = FALSE}
set.seed(123)

x1 = lubom0 %>% 
  tax_filter(min_prevalence = 0.05) %>% 
  tax_transform("compositional") %>% 
  subset_samples(!is.na(PD)) %>% 
  otu_table() %>% 
  as.data.frame() %>% 
  as.matrix()

x2 = aho %>% 
  tax_filter(min_prevalence = 0.05) %>% 
  tax_transform("compositional") %>% 
  subset_samples(!is.na(PD)) %>% 
  otu_table() %>% 
  as.data.frame() %>% 
  as.matrix()

cpop_x1 = log2(x1 + 0.01)
cpop_x2 = log2(x2 + 0.01)

cpop_common_tax = intersect(colnames(x1), colnames(x2))

cpop_x1 = cpop_x1[, cpop_common_tax]
cpop_x2 = cpop_x2[, cpop_common_tax]

# update cpop common taxa = remove taxa with the small variance of abundance
# those taxa are not helpful in distinguishing PD from HC due to small variance
cpop_common_tax = intersect(names(apply(cpop_x1, 2, function(x) var(x))[apply(cpop_x1, 2, function(x) var(x) >= 0.08)]),
                            names(apply(cpop_x2, 2, function(x) var(x))[apply(cpop_x2, 2, function(x) var(x) >= 0.08)]))

cpop_x1 = cpop_x1[, cpop_common_tax]
cpop_x2 = cpop_x2[, cpop_common_tax]

y1 = lubom0 %>% 
  subset_samples(!is.na(PD)) %>% 
  samdat_tbl() %>% 
  mutate(PD = as.factor(case_when(PD == "PD" ~ 1,
                                  TRUE ~ 0))) %>% 
  pull(PD)

y2 = aho %>% 
  subset_samples(!is.na(PD)) %>% 
  samdat_tbl() %>% 
  mutate(PD = as.factor(case_when(PD == "PD" ~ 1,
                                  TRUE ~ 0))) %>% 
  pull(PD)

cpop_pred_result_mad = list()
cpop_pred_result_msd = list()
cpop_pred_result_t = list()

for (i in 1:length(eval_trio_list)) {
  # get OTU table
  eval_data = eval_trio_list[[i]]$evalData
  
  # find common taxa
  new_common_tax = intersect(cpop_common_tax, colnames(eval_data))
  eval_data = log2(eval_data[, new_common_tax] + 0.01)
  
  # mean absolute difference weight model
  cpop_mad = cpop_model(x1 = cpop_x1[, new_common_tax], x2 = cpop_x2[, new_common_tax],
                        y1 = y1, y2 = y2,
                        family = "binomial")
  
  # construct log-ratio matrices
  z1 = pairwise_col_diff(cpop_x1[, new_common_tax])
  z2 = pairwise_col_diff(cpop_x2[, new_common_tax])
  
  # calculate mean squared error
  w_msd = (colMeans(z1) - colMeans(z2))^2
  
  # mse weight model
  cpop_msd = cpop_model(x1 = cpop_x1[, new_common_tax], x2 = cpop_x2[, new_common_tax],
                        y1 = y1, y2 = y2,
                        w = w_msd,
                        family = "binomial")
  
  for (j in 1:20) {
    # subset evalData
    subset_id = sample(1:nrow(eval_data), round(nrow(eval_data)*0.8))
    subset_eval_data = eval_data[subset_id, ]
    
    pred_mad = CPOP::predict_cpop(cpop_mad, newx = subset_eval_data)$cpop_model_avg_class
    pred_mad = setNames(pred_mad, subset_id) # store the corresponding subset_id for each prediction outcome
    
    pred_msd = CPOP::predict_cpop(cpop_msd, newx = subset_eval_data)$cpop_model_avg_class
    pred_msd = setNames(pred_msd, subset_id) # store the corresponding subset_id for each prediction outcome
    
    cpop_pred_result_mad = append(cpop_pred_result_mad, list(data_name = pred_mad))
    names(cpop_pred_result_mad)[length(names(cpop_pred_result_mad))] = names(eval_trio_list)[[i]]
    
    cpop_pred_result_msd = append(cpop_pred_result_msd, list(data_name = pred_msd))
    names(cpop_pred_result_msd)[length(names(cpop_pred_result_msd))] = names(eval_trio_list)[[i]]
  }
}
```

### MPOP

```{r, message = FALSE}
set.seed(123)

mpop_x1 = lubom0 %>% 
  tax_filter(min_prevalence = 0.05) %>% 
  subset_samples(!is.na(PD)) %>% 
  otu_table() %>% 
  as.data.frame() %>% 
  as.matrix()

lubom0_tax = colnames(mpop_x1)

mpop_x1 = log2(mpop_x1 + 0.01)
mpop_x1 = t(apply(mpop_x1, 1, function(x) scale(x)))
colnames(mpop_x1) = lubom0_tax

mpop_x2 = aho %>% 
  tax_filter(min_prevalence = 0.05) %>% 
  subset_samples(!is.na(PD)) %>% 
  otu_table() %>% 
  as.data.frame() %>% 
  as.matrix()

aho_tax = colnames(mpop_x2)

mpop_x2 = log2(mpop_x2 + 0.01)
mpop_x2 = t(apply(mpop_x2, 1, function(x) scale(x)))
colnames(mpop_x2) = aho_tax

mpop_common_tax = intersect(lubom0_tax, aho_tax)

mpop_x1 = mpop_x1[, mpop_common_tax]
mpop_x2 = mpop_x2[, mpop_common_tax]

# similar to cpop common taxa, update mpop common taxa based on the variance of taxa abundance
mpop_common_tax = intersect(names(apply(mpop_x1, 2, function(x) var(x))[apply(mpop_x1, 2, function(x) var(x) >= 0.08)]),
                            names(apply(mpop_x2, 2, function(x) var(x))[apply(mpop_x2, 2, function(x) var(x) >= 0.08)]))

mpop_x1 = mpop_x1[, mpop_common_tax]
mpop_x2 = mpop_x2[, mpop_common_tax]

# mpop y is numeric due to the zero-sum regression-based method
mpop_y1 = lubom0 %>% 
  subset_samples(!is.na(PD)) %>% 
  samdat_tbl() %>% 
  mutate(PD = case_when(PD == "PD" ~ 1,
                        TRUE ~ 0)) %>% 
  pull(PD)

mpop_y2 = aho %>% 
  subset_samples(!is.na(PD)) %>% 
  samdat_tbl() %>% 
  mutate(PD = case_when(PD == "PD" ~ 1,
                        TRUE ~ 0)) %>% 
  pull(PD)

mpop_pred_result = list()

for (i in 1:length(eval_trio_list)) {
  # get OTU table
  eval_data = eval_trio_list[[i]]$evalData
  
  # find common taxa
  new_common_tax = intersect(mpop_common_tax, colnames(eval_data))
  eval_data = log2(eval_data[, new_common_tax] + 1)
  
  # MPOP data preprocessing
  eval_data = t(apply(eval_data, 1, function(x) scale(x)))
  colnames(eval_data) = new_common_tax
  
  mpop_fit = mpop_model(x1 = mpop_x1[, new_common_tax], x2 = mpop_x2[, new_common_tax],
                        y1 = mpop_y1, y2 = mpop_y2,
                        family = "binomial")
  
  for (j in 1:20) {
    # subset evalData
    subset_id = sample(1:nrow(eval_data), round(nrow(eval_data)*0.8))
    subset_eval_data = eval_data[subset_id, ]
    
    pred = predict_mpop(mpop_fit, newx = subset_eval_data)$mpop_model_avg_class
    pred = setNames(pred, subset_id) # store the corresponding subset_id for each prediction outcome
    
    mpop_pred_result = append(mpop_pred_result, list(data_name = pred))
    names(mpop_pred_result)[length(names(mpop_pred_result))] = names(eval_trio_list)[[i]]
  }
}
```

### LASSO

```{r}
set.seed(123)

lasso_pred_result_min = list()
lasso_pred_result_1se = list()

for (i in 1:length(eval_trio_list)) {
  # get OTU table
  eval_data = eval_trio_list[[i]]$evalData
  
  # find common taxa
  common_tax = intersect(colnames(x1), colnames(eval_data))
  eval_data = eval_data[, common_tax]
  
  lasso_obj = cv.glmnet(x1[, common_tax], y1, family = "binomial", alpha = 1, type.measure = "class")
  
  for (j in 1:20) {
    # subset evalData
    subset_id = sample(1:nrow(eval_data), round(nrow(eval_data)*0.8))
    subset_eval_data = eval_data[subset_id, ]
    
    pred_min = as.vector(round(predict(lasso_obj, subset_eval_data, s = "lambda.min", type = "response")))
    pred_min = setNames(pred_min, subset_id) # store the corresponding subset_id for each prediction outcome
    
    pred_1se = as.vector(round(predict(lasso_obj, subset_eval_data, s = "lambda.1se", type = "response")))
    pred_1se = setNames(pred_1se, subset_id)
    
    lasso_pred_result_min = append(lasso_pred_result_min, list(data_name = pred_min))
    names(lasso_pred_result_min)[length(names(lasso_pred_result_min))] = names(eval_trio_list)[[i]]
    
    lasso_pred_result_1se = append(lasso_pred_result_1se, list(data_name = pred_1se))
    names(lasso_pred_result_1se)[length(names(lasso_pred_result_1se))] = names(eval_trio_list)[[i]]
  }
}
```

### NetCoMi

```{r}
lubom0_pd = lubom0 %>% 
  subset_samples(!is.na(PD)) %>% 
  tax_filter(min_prevalence = 0.05) %>% 
  subset_samples(PD == "PD")

lubom0_hc = lubom0 %>% 
  subset_samples(!is.na(PD)) %>% 
  tax_filter(min_prevalence = 0.05) %>% 
  subset_samples(PD == "HC")

lubom0_net1 = netConstruct(data = lubom0_pd, 
                           data2 = lubom0_hc,
                           measure = "pearson",
                           normMethod = "TSS", 
                           zeroMethod = "none",
                           sparsMethod = "threshold",
                           thresh = 0.4,
                           verbose = 1,
                           seed = 123)

props_season1 = netAnalyze(lubom0_net1, clustMethod = "cluster_fast_greedy")
lubom0_net1_sum = summary(props_season1, showCentr = c("degree", "eigenvector"))

hub1 = lubom0_net1_sum$hubs %>% 
  pull("group '1'")

hub2 = lubom0_net1_sum$hubs %>% 
  pull("group '2'")

lubom_net_features = union(hub1, hub2)

netcomi_pred_result1 = list()

for (i in 1:length(eval_trio_list)) {
  # get OTU table
  eval_data = eval_trio_list[[i]]$evalData
  
  # find common taxa
  common_tax = intersect(lubom_net_features, colnames(eval_data))
  
  # subset eval_data
  eval_data = eval_data[, common_tax]
  
  ridge_fit = cv.glmnet(x1[, common_tax], y1, family = "binomial", alpha = 0, type.measure = "class")
  
  for (j in 1:20) {
    # subset evalData
    subset_id = sample(1:nrow(eval_data), round(nrow(eval_data)*0.8))
    subset_eval_data = eval_data[subset_id, ]
    
    pred = as.vector(round(predict(ridge_fit, subset_eval_data, s = "lambda.min", type = "response")))
    pred = setNames(pred, subset_id) # store the corresponding subset_id for each prediction outcome
    
    netcomi_pred_result1 = append(netcomi_pred_result1, list(data_name = pred))
    names(netcomi_pred_result1)[length(names(netcomi_pred_result1))] = names(eval_trio_list)[[i]]
  }
}
```

```{r}
lubom0_net2 = netConstruct(data = lubom0_pd, 
                           data2 = lubom0_hc,
                           measure = "pearson",
                           normMethod = "clr", 
                           zeroMethod = "none",
                           sparsMethod = "threshold",
                           thresh = 0.4,
                           verbose = 1,
                           seed = 123)

props_season2 = netAnalyze(lubom0_net2, clustMethod = "cluster_fast_greedy")
lubom0_net2_sum = summary(props_season2, showCentr = c("degree", "eigenvector"))

hub1 = lubom0_net2_sum$hubs %>% 
  pull("group '1'")

hub2 = lubom0_net2_sum$hubs %>% 
  pull("group '2'")

lubom_net_features = union(hub1, hub2)

netcomi_pred_result2 = list()

for (i in 1:length(eval_trio_list)) {
  # get OTU table
  eval_data = eval_trio_list[[i]]$evalData
  
  # find common taxa
  common_tax = intersect(lubom_net_features, colnames(eval_data))
  
  # subset eval_data
  eval_data = eval_data[, common_tax]
  
  ridge_fit = cv.glmnet(x1[, common_tax], y1, family = "binomial", alpha = 0, type.measure = "class")
  
  for (j in 1:20) {
    # subset evalData
    subset_id = sample(1:nrow(eval_data), round(nrow(eval_data)*0.8))
    subset_eval_data = eval_data[subset_id, ]
    
    pred = as.vector(round(predict(ridge_fit, subset_eval_data, s = "lambda.min", type = "response")))
    pred = setNames(pred, subset_id) # store the corresponding subset_id for each prediction outcome
    
    netcomi_pred_result2 = append(netcomi_pred_result2, list(data_name = pred))
    names(netcomi_pred_result2)[length(names(netcomi_pred_result2))] = names(eval_trio_list)[[i]]
  }
}
```

```{r}
# combine prediction results
method_list = Map(function(a, b, c, d, e, f, g) list("CPOP\nMAD"= a,
                                                     "CPOP\nMSD" = b,
                                                     "MPOP" = c,
                                                     "LASSO\nlambda.min" = d,
                                                     "LASSO\nlamdba.1se" = e,
                                                     "NetCoMi\nTSS" = f,
                                                     "NetCoMi\nCLR" = g),
                  cpop_pred_result_mad,
                  cpop_pred_result_msd,
                  mpop_pred_result,
                  lasso_pred_result_min, 
                  lasso_pred_result_1se,
                  netcomi_pred_result1,
                  netcomi_pred_result2)
```

```{r}
# users will need to create a lst of arguments to their own task function (e.g. class_acc_calculator)
# for example, class_acc_calculator requires two inputs: prediction result and gold standard result
# since each method for each data has different prediction result
# I put them into a list of nested lists
# outer list elements: data, inner list elements: method
# then the elements of inner list will contain the argument list

# create an empty argument list
class_args_list = list()

for (i in 1:length(method_list)) {
  # get the data name
  data_name = names(method_list)[[i]]
  
  # get the evalTask object for the current data
  eval_task = eval_trio_list[[data_name]]$evalTaskList[["Stability"]]
  
  method_args_list = list()
  for (j in 1:length(method_list[[i]])) {
    # get the prediction result
    pred = method_list[[i]][[j]]
    
    # get subset id for each prediction outcome at each iteration
    subset_id = as.numeric(names(method_list[[i]][[j]]))
      
    # get a subset of gsResult from the eval_task object
    gs_result_susbet = eval_task$gsResultSubset(subset_id)
    
    # argument list
    args = list(pred = pred, gs_result = gs_result_susbet)
    
    # get the method name
    method_name = names(method_list[[i]])[[j]]
    
    method_args_list[[method_name]] = args
  }
  class_args_list = append(class_args_list, list(data_name = method_args_list))
  names(class_args_list)[length(class_args_list)] = names(method_list)[[i]]
}
```

## Model Evaluation

```{r, message = FALSE, warning = FALSE, results = "asis"}
evalStudy(eval_trio_list = eval_trio_list,
          method_list = method_list,
          task_name = "Stability",
          task_fun = class_acc_calculator,
          args_list = class_args_list)
```


### Lubomski 6

```{r}
lubom6_res_df = eval_trio_list[[2]]$evalTaskList[[1]]$evalResult %>% 
  select(Method, F1, AUC) %>% 
  group_by(Method) %>% 
  summarize(F1 = median(F1), 
            AUC = median(AUC))

lubom6_res = lubom6_res_df %>% 
  kbl(caption = "Lubomski 6 accuracy performance table",  
      align = c("l", "c"),
      digits = 3,
      escape = TRUE,
      table.attr = "style='width:70%;'") %>% 
  kable_classic_2(full_width = TRUE, html_font = "Times New Roman Bold", font_size = 16) %>% 
  row_spec(0, bold = T)

# save_kable(lubom6_res, "lubom6_result.pdf")

lubom6_res_df %>% 
  mutate(method_category = case_when(Method == "CPOP\nMAD" ~ "Edge-only",
                                     Method == "CPOP\nMSD" ~ "Edge-only",
                                     Method == "LASSO\nlambda.min" ~ "Node-only",
                                     Method == "LASSO\nlamdba.1se" ~ "Node-only",
                                     Method == "MPOP" ~ "Node-only",
                                     TRUE ~ "Node + Edge")) %>% 
  ggplot() +
  aes(x = Method, y = F1, fill = method_category) +
  geom_bar(stat = "identity") +
  labs(fill = "Method Category") +
  scale_fill_viridis(discrete = TRUE,
                     option = "plasma") +
  theme(axis.text.x = element_text(size = 12),
        axis.title.x = element_text(size = 15),
        axis.text.y = element_text(size = 12),
        axis.title.y = element_text(size = 15),
        legend.position = "none")

eval_trio_list[[2]]$evalTaskList[[1]]$evalResult %>% 
  select(Method, F1) %>% 
  mutate(method_category = case_when(Method == "CPOP\nMAD" ~ "Edge-only",
                                     Method == "CPOP\nMSD" ~ "Edge-only",
                                     Method == "LASSO\nlambda.min" ~ "Node-only",
                                     Method == "LASSO\nlamdba.1se" ~ "Node-only",
                                     Method == "MPOP" ~ "Node-only",
                                     TRUE ~ "Node + Edge")) %>% 
  ggplot() +
  aes(x = Method, y = F1, fill = method_category) +
  geom_boxplot(alpha = 0.7) +
  labs(fill = "Method Category") +
  scale_fill_viridis(discrete = TRUE,
                     option = "plasma") +
  scale_y_continuous(limits = c(0.45, 0.8)) +
  theme(axis.text.x = element_text(size = 12),
        axis.title.x = element_text(size = 15),
        axis.text.y = element_text(size = 12),
        axis.title.y = element_text(size = 15),
        legend.position = "none")
```

### Lubomski 12

```{r}
lubom12_res_df = eval_trio_list[[3]]$evalTaskList[[1]]$evalResult %>% 
  select(Method, F1, AUC) %>% 
  group_by(Method) %>% 
  summarize(F1 = median(F1),
            AUC = median(AUC))

lubom12_res = lubom12_res_df %>% 
  kbl(caption = "Lubomski 12 accuracy performance table",  
      align = c("l", "c"),
      digits = 3,
      escape = TRUE,
      table.attr = "style='width:70%;'") %>% 
  kable_classic_2(full_width = TRUE, html_font = "Times New Roman Bold", font_size = 16) %>% 
  row_spec(0, bold = T)

# save_kable(lubom12_res, "lubom12_result.pdf")

lubom12_res_df

lubom12_res_df %>% 
  mutate(method_category = case_when(Method == "CPOP\nMAD" ~ "Edge-only",
                                     Method == "CPOP\nMSD" ~ "Edge-only",
                                     Method == "LASSO\nlambda.min" ~ "Node-only",
                                     Method == "LASSO\nlamdba.1se" ~ "Node-only",
                                     Method == "MPOP" ~ "Node-only",
                                     TRUE ~ "Node + Edge")) %>% 
  ggplot() +
  aes(x = Method, y = F1, fill = method_category) +
  geom_bar(stat = "identity") +
  labs(fill = "Method Category") +
  scale_fill_viridis(discrete = TRUE,
                     option = "plasma") +
  theme(axis.text.x = element_text(size = 12),
        axis.title.x = element_text(size = 15),
        axis.text.y = element_text(size = 12),
        axis.title.y = element_text(size = 15),
        legend.position = "none")

eval_trio_list[[3]]$evalTaskList[[1]]$evalResult %>% 
  select(Method, F1) %>% 
  mutate(method_category = case_when(Method == "CPOP\nMAD" ~ "Edge-only",
                                     Method == "CPOP\nMSD" ~ "Edge-only",
                                     Method == "LASSO\nlambda.min" ~ "Node-only",
                                     Method == "LASSO\nlamdba.1se" ~ "Node-only",
                                     Method == "MPOP" ~ "Node-only",
                                     TRUE ~ "Node + Edge")) %>% 
  ggplot() +
  aes(x = Method, y = F1, fill = method_category) +
  geom_boxplot(alpha = 0.7) +
  labs(fill = "Method Category") +
  scale_fill_viridis(discrete = TRUE,
                     option = "plasma") +
  theme(axis.text.x = element_text(size = 12),
        axis.title.x = element_text(size = 15),
        axis.text.y = element_text(size = 12),
        axis.title.y = element_text(size = 15),
        legend.position = "none")
```

### Aho

```{r}
aho_res_df = eval_trio_list[[4]]$evalTaskList[[1]]$evalResult %>% 
  select(Method, F1, AUC) %>% 
  group_by(Method) %>% 
  summarize(F1 = median(F1), 
            AUC = median(AUC))

aho_res = aho_res_df %>% 
  kbl(caption = "Aho accuracy performance table",  
      align = c("l", "c", "c", "c", "c", "c", "c"),
      digits = 3,
      escape = TRUE,
      table.attr = "style='width:70%;'") %>% 
  kable_classic_2(full_width = TRUE, html_font = "Times New Roman Bold", font_size = 16) %>% 
  row_spec(0, bold = T)

# save_kable(aho_res, "aho_result.pdf")

aho_res_df

aho_res_df %>% 
  mutate(method_category = case_when(Method == "CPOP\nMAD" ~ "Edge-only",
                                     Method == "CPOP\nMSD" ~ "Edge-only",
                                     Method == "LASSO\nlambda.min" ~ "Node-only",
                                     Method == "LASSO\nlamdba.1se" ~ "Node-only",
                                     Method == "MPOP" ~ "Node-only",
                                     TRUE ~ "Node + Edge")) %>% 
  ggplot() +
  aes(x = Method, y = F1, fill = method_category) +
  geom_bar(stat = "identity") +
  labs(fill = "Method Category") +
  scale_fill_viridis(discrete = TRUE,
                     option = "plasma") +
  scale_y_continuous(limits = c(0, 0.8)) +
  theme(axis.text.x = element_text(size = 12),
        axis.title.x = element_text(size = 15),
        axis.text.y = element_text(size = 12),
        axis.title.y = element_text(size = 15),
        legend.position = "none")

eval_trio_list[[4]]$evalTaskList[[1]]$evalResult %>% 
  select(Method, F1) %>% 
  mutate(method_category = case_when(Method == "CPOP\nMAD" ~ "Edge-only",
                                     Method == "CPOP\nMSD" ~ "Edge-only",
                                     Method == "LASSO\nlambda.min" ~ "Node-only",
                                     Method == "LASSO\nlamdba.1se" ~ "Node-only",
                                     Method == "MPOP" ~ "Node-only",
                                     TRUE ~ "Node + Edge")) %>% 
  ggplot() +
  aes(x = Method, y = F1, fill = method_category) +
  geom_boxplot(alpha = 0.7) +
  labs(fill = "Method Category") +
  scale_fill_viridis(discrete = TRUE,
                     option = "plasma") +
  scale_y_continuous(limits = c(0.45, 0.8)) +
  theme(axis.text.x = element_text(size = 12),
        axis.title.x = element_text(size = 15),
        axis.text.y = element_text(size = 12),
        axis.title.y = element_text(size = 15),
        legend.position = "none")
```

```{r}
lubom6_stab_res = eval_trio_list[[2]]$evalTaskList[[1]]$evalResult %>% 
  group_by(Method) %>% 
  summarize(F1 = sd(F1))

lubom12_stab_res = eval_trio_list[[3]]$evalTaskList[[1]]$evalResult %>% 
  group_by(Method) %>% 
  summarize(F1 = sd(F1)) %>% 
  select(-Method)

aho_stab_res = eval_trio_list[[4]]$evalTaskList[[1]]$evalResult %>% 
  group_by(Method) %>% 
  summarize(F1 = sd(F1)) %>% 
  select(-Method)

stab_res = cbind(lubom6_stab_res, lubom12_stab_res, aho_stab_res) %>% 
  kbl(col.names = c("Method", "Lubomski 6 SD of F1", "Lubomski 12 SD of F1", "Aho SD of F1"),
      align = c("l", "c", "c", "c"),
      digits = 3,
      escape = TRUE) %>% 
  kable_classic_2(full_width = TRUE, html_font = "Times New Roman Bold", font_size = 16) %>% 
  row_spec(0, bold = T)

# save_kable(stab_res, "stability_result.pdf")
```

```{r}
eval_trio_list[[4]]$evalTaskList[[1]]$evalResult %>% 
  group_by(Method) %>% 
  summarize(Accuracy = sd(Accuracy),
            Sensitivity = sd(Sensitivity),
            Specificity = sd(Specificity),
            F1 = sd(F1),
            `Balanced Accuracy` = sd(`Balanced Accuracy`),
            AUC = sd(AUC)) %>% 
  arrange(AUC)
```


# Single-cell Evaluation Framework

```{r}
eh = ExperimentHub()
sb_data = query(eh, "SimBenchData")
eh5385 = sb_data[["EH5385"]]
eh5391 = sb_data[["EH5391"]]
```

```{r}
# filter out unwanted cells
eh5385 = subset(eh5385, subset = nFeature_RNA > 200 & nFeature_RNA < 2500)
eh5391 = subset(eh5391, subset = nFeature_RNA > 200 & nFeature_RNA < 2500)

sc_list = list(`293T Cell Line` = eh5385,
               `Breast Cell Line` = eh5391)
```

```{r}
# generate evalTrio objects for all the data and put them into a list
sc_eval_trio_list = list()

for (i in 1:length(sc_list)) {
  # get cell types
  Idents(sc_list[[i]]) = "celltype"
  
  # select one cell type
  cell_type = unique(sc_list[[i]]$celltype)[1]
  
  # generate a null dataset with the selected cell type
  null_data = subset(sc_list[[i]], idents = cell_type)
  random_groups = sample(c("Group 1", "Group 2"), size = ncol(null_data), replace = TRUE)
  Idents(null_data) = random_groups
  
  # get the null data expression matrix
  gs_result = as(null_data[["RNA"]]$counts, "matrix")
  
  # create an evalTask object
  eval_task = evalTask_obj_generator(task_name = "DE Analysis",
                                     gs_result = gs_result)
  eval_task_list = list(eval_task)
  
  # get the name of current single-cell data
  data_name = names(sc_list)[[i]]
  
  # create an evalTrio object
  eval_trio = evalTrio_obj_generator(eval_data = null_data,
                                     data_name = data_name,
                                     organism = "Human",
                                     research_area = "Single-cell",
                                     eval_task_list = eval_task_list)
  sc_eval_trio_list[[data_name]] = eval_trio
}
```

## Seurat DE Analysis

```{r}
seurat_de_result = list()
for (i in 1:length(sc_eval_trio_list)) {
  data = sc_eval_trio_list[[i]]$evalData
  data = NormalizeData(data, normalization.method = "LogNormalize", scale.factor = 10000)
  
  de_result = Seurat::FindMarkers(data, ident.1 = "Group 1", ident.2 = "Group 2")
  de_genes = rownames(subset(de_result, p_val_adj <= 0.05))
  
  seurat_de_result[[names(sc_eval_trio_list)[[i]]]] = de_genes
}
```

## Limma DE Analysis

```{r}
limma_de_result = list()
for (i in 1:length(sc_eval_trio_list)) {
  data = sc_eval_trio_list[[i]]$evalData
  
  exprs_mat = data[["RNA"]]$counts
  group = unname(Idents(data))
  
  design = model.matrix(~group)
  fit = eBayes(lmFit(exprs_mat, design))
  
  de_result = topTable(fit, n = Inf)
  de_genes = de_result %>% 
    filter(adj.P.Val <= 0.05) %>% 
    rownames()
  
  limma_de_result[[names(sc_eval_trio_list)[[i]]]] = de_genes
}
```

```{r}
de_method_list = Map(function(x, y) list(Seurat = x,
                                         Limma = y),
                     seurat_de_result, limma_de_result)
```

```{r}
# create an empty argument list
de_args_list = list()

for (i in 1:length(sc_eval_trio_list)) {
  # extract the expression matrix from each evalTrio object
  exprs_mat = sc_eval_trio_list[[i]]$evalData[["RNA"]]$counts
  
  # get the name of the current evalTrio object = data name
  data_name = names(sc_eval_trio_list)[[i]]
  
  # with the data name above, create an element of the args_list, which is also a list that will store the argument list
  de_args_list[[data_name]] = list()
  for (j in 1:length(de_method_list[[i]])) {
    # extract the prediction result from each method (j) for each data (i)
    pred = de_method_list[[i]][[j]]
    
    # get the name of the current prediction result = method name
    method_name = names(de_method_list[[i]])[[j]]
    
    # store the argument list for each data and each method combination   
    de_args_list[[data_name]][[method_name]] = list(exprs_mat, pred)
  }
}

de_method_list[[1]]
```

```{r, results = "asis"}
evalStudy(eval_trio_list = sc_eval_trio_list,
          method_list = de_method_list,
          task_name = "DE Analysis",
          task_fun = de_fp_calculator,
          args_list = de_args_list)
```


```{r}
eval_trio_list[[1]]$evalTaskList[[1]]$evalResult
```

