[{"path":"https://sydneybiox.github.io/BenchHub/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2024 TrioR authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/articles/v01_intro_trio.html","id":"motivation","dir":"Articles","previous_headings":"","what":"Motivation","title":"1 Introduction to the Trio Class","text":"BenchHub R ecosystem built make benchmarking easier. organizes data, evaluation metrics, gold standards (auxiliary data), even provides built-visualization tools help interpret results. BenchHub, researchers can quickly compare new methods, gain insights, produce trustworthy benchmarking studies.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/articles/v01_intro_trio.html","id":"creating-trio-object","dir":"Articles","previous_headings":"","what":"Creating Trio object","title":"1 Introduction to the Trio Class","text":"Trio objects can created using Trio$new constructor. 3 ways create Trio object: Curated Trio Datasets Source ID Load object directly dataset can’t loaded using Trio’s inbuilt loader, custom loader can provided.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/articles/v01_intro_trio.html","id":"method-1-curated-trio-datasets","dir":"Articles","previous_headings":"Creating Trio object","what":"Method 1: Curated Trio Datasets","title":"1 Introduction to the Trio Class","text":"can directly use name Curated Trio Datasets sheet initialise Trio object populated metrics auxiliary data. method useful want quickly start predefined dataset. output shows Trio dataset, metrics, auxiliary data. dataset contains 137 rows 9 columns, metrics auxiliary data already populated printed. Trio ready use survival prediction evaluation.","code":"tempCache <- tempdir() trio <- Trio$new(\"Veteran_data\", cachePath = tempCache)  trio ##  ## ── Trio Object ───────────────────────────────────────────────────────────────── ##  ## ── Dataset  ## Dataset Details: ##   spc_tbl_ [137 × 9] (S3: spec_tbl_df/tbl_df/tbl/data.frame) ##   - attr(*, \"spec\")= ##   .. cols( ##   ..  ...1 = col_double(), ##   ..  trt = col_double(), ##   ..  celltype = col_double(), ##   ..  time = col_double(), ##   ..  status = col_double(), ##   ..  karno = col_double(), ##   ..  diagtime = col_double(), ##   ... (truncated) ## Data Source: \"figshare\" ## Dataset ID: \"26142922/47361073\" ## Cache Path: \"/tmp/RtmpHZDBbD\" ## Split Indices: \"None\" ##  ## ── Auxilliary Data  ## Number of Auxiliary Data: 1 ## Names of Auxiliary Data: \"survival_data\" ##  ## ── Metrics  ## Number of Metrics: 6 ## Names of Metrics: \"harrell_cindex\", \"begg_cindex\", \"uno_cindex\", \"gh_cindex\", ## \"brier_score\", and \"time_dep_auc\""},{"path":"https://sydneybiox.github.io/BenchHub/articles/v01_intro_trio.html","id":"method-2-source-and-id","dir":"Articles","previous_headings":"Creating Trio object","what":"Method 2: Source and ID","title":"1 Introduction to the Trio Class","text":"Trio objects can created specifying ID source valid trio downloader. method useful specific dataset ID supported source like Figshare, GEO, ExperimentHub. example, dataset ID Figshare, GEO, ExperimentHub, can create Trio object follows: fileID can optionally provided specify specific file collection. Supplementary_filename can optionally provided specify specific supplementary file series. experiementhub: Trio$new(\"experiementhub:experimenthubID\") example shows create Trio object using Figshare dataset fileID.","code":"trioA <- Trio$new(\"figshare:26142922/47361079\", cachePath = tempCache)  trioA ##  ## ── Trio Object ───────────────────────────────────────────────────────────────── ##  ## ── Dataset  ## Dataset Details: ##   spc_tbl_ [58 × 19,820] (S3: spec_tbl_df/tbl_df/tbl/data.frame) ##   - attr(*, \"spec\")= ##   .. cols( ##   ..  ...1 = col_character(), ##   ..  A1BG = col_double(), ##   ..  `A1BG-AS1` = col_double(), ##   ..  A1CF = col_double(), ##   ..  A2M = col_double(), ##   ..  `A2M-AS1` = col_double(), ##   ..  A2ML1 = col_double(), ##   ... (truncated) ## Data Source: \"figshare\" ## Dataset ID: \"26142922/47361079\" ## Cache Path: \"/tmp/RtmpHZDBbD\" ## Split Indices: \"None\" ##  ## ── Auxilliary Data  ## Number of Auxiliary Data: 0 ## Names of Auxiliary Data: ##  ## ── Metrics  ## Number of Metrics: 0 ## Names of Metrics:"},{"path":"https://sydneybiox.github.io/BenchHub/articles/v01_intro_trio.html","id":"method-3-load-an-object-directly","dir":"Articles","previous_headings":"Creating Trio object","what":"Method 3: Load an object directly","title":"1 Introduction to the Trio Class","text":"Trio can also created passing object directly constructor. method useful already dataset loaded R environment want use Trio. dataset, can easily create trio object well. example using microbiome dataset.","code":"data(\"lubomski_microbiome_data\", package = \"BenchHub\") trioB <- Trio$new(data = lubomPD, datasetID = \"lubomski_microbiome\") trioB ##  ## ── Trio Object ───────────────────────────────────────────────────────────────── ##  ## ── Dataset  ## Dataset Details: ##   Factor w/ 2 levels \"0\",\"1\": 2 1 2 1 2 2 1 2 2 1 ... ## Data Source: ## Dataset ID: \"lubomski_microbiome\" ## Cache Path: ## Split Indices: \"None\" ##  ## ── Auxilliary Data  ## Number of Auxiliary Data: 0 ## Names of Auxiliary Data: ##  ## ── Metrics  ## Number of Metrics: 0 ## Names of Metrics:"},{"path":"https://sydneybiox.github.io/BenchHub/articles/v01_intro_trio.html","id":"bonus-using-a-custom-loader","dir":"Articles","previous_headings":"Creating Trio object","what":"Bonus: Using a custom loader","title":"1 Introduction to the Trio Class","text":"Trio supports custom loaders data formats directly supported Trio. loader function takes path, provided downloader, returns object loaded Trio. , use anonymous function wrap GEOquery::getGEO provide path downloaded file.","code":"# This code will not run as it requires a GEO dataset to be downloaded # GEO is unreliable trioGEO <- Trio$new(   \"GEO:GSE46474\",   dataLoader = \\(path) suppressMessages(GEOquery::getGEO(filename = path)),   cachePath = tempdir() )  trioGEO"},{"path":[]},{"path":"https://sydneybiox.github.io/BenchHub/articles/v01_intro_trio.html","id":"adding-metrics","dir":"Articles","previous_headings":"Adding components to Trio","what":"Adding metrics","title":"1 Introduction to the Trio Class","text":"benchmarking studies, metric refers measurement used evaluate specific task. example, define task called survival model prediction. Trio, metric pairwise function form f(expected, predicted) returns single value. can also add metrics additional arguments passing list arguments args parameter. example, added two metrics based function: “equality” “inequality”. “equality” metric checks expected predicted values equal, “inequality” metric checks equal. Underneeth hood, Trio creates wrapper function calls metric function specified arguments.","code":"eq <- \\(expected, predicted, inequality = FALSE) {   if (inequality) {     return(!expected == predicted)   }    expected == predicted }  trio$addMetric(\"equality\", eq)  # Trio also supports passing through arguments to a metric # Note: parameter names added for clarity trio$addMetric(   name = \"inequality\", metric = eq, args = list(inequality = TRUE) ) trio$metrics$inequality ## function (auxData, to_eval)  ## { ##     do.call(metric, append(list(auxData, to_eval), args)) ## } ## <environment: 0x560075837278>"},{"path":"https://sydneybiox.github.io/BenchHub/articles/v01_intro_trio.html","id":"adding-and-getting-auxdata","dir":"Articles","previous_headings":"Adding components to Trio","what":"Adding and getting auxData","title":"1 Introduction to the Trio Class","text":"auxData (Auxiliary Data) refers gold standard evaluation tasks falls two categories: Internal: Extracted directly Trio dataset. may include metadata cell types (e.g., B cells, CD4, CD8), patient conditions (e.g., healthy, disease), spatial domain information. specific content depends dataset . External: Retrieved external databases, disease pathway databases gene marker databases. equality inequality metrics added , can now run evaluation. First add auxiliary data Trio object evaluate . Auxiliary data data allows make evaluation. Auxiliary data added linked metrics allow evaluate . view auxiliary data one can use getAuxData.","code":"# It can be a fixed quantity trio$addAuxData(   name = \"Number One\", auxData = 1, metrics = c(\"equality\", \"inequality\") )  # Or it can be a function that acts on the data trio$addAuxData(   name = \"length\", auxData = length, metrics = c(\"equality\", \"inequality\") ) trio$getAuxData(\"length\") # This is equivalent to `length(trio$data)` ## [1] 9"},{"path":"https://sydneybiox.github.io/BenchHub/articles/v01_intro_trio.html","id":"evaluation-example","dir":"Articles","previous_headings":"Adding components to Trio","what":"Evaluation Example","title":"1 Introduction to the Trio Class","text":"Trio set relevant metrics auxData, ready evaluate. simple evaluation: multi-method evaluation: detailed look evaluation using Trio, please refer vignette 2.","code":"result <- trio$evaluate(list(\"Number One\" = 1, length = 182)) knitr::kable(result) result <- trio$evaluate(list(   great_method = list(\"Number One\" = 1, length = 575),   poor_method = list(\"Number One\" = 2, length = 182) )) knitr::kable(result)"},{"path":[]},{"path":"https://sydneybiox.github.io/BenchHub/articles/v01_intro_trio.html","id":"caching","dir":"Articles","previous_headings":"Other Features","what":"Caching","title":"1 Introduction to the Trio Class","text":"Trio uses caching avoid lengthy downloads first time data set accessed. cachePath parameter specifies path cache directory. specified, cache directory defaults ~/.cache/R/TrioR/.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/articles/v01_intro_trio.html","id":"data-splitting","dir":"Articles","previous_headings":"Other Features","what":"Data Splitting","title":"1 Introduction to the Trio Class","text":"Trio supports data splitting cross-validation. split method splits data training test sets cross-validation. splitIndices attribute stores indices sample. Indices generated using splitTools package. split method takes outcome variable number folds repeats. stratify parameter can used stratify outcome variable.","code":"trio$split(y = 1:137, n_fold = 2, n_repeat = 5, seed = 1234, stratify = FALSE) trio$splitIndices ## $Fold1.Rep1 ##  [1]   2   3   4   5   6   7   8   9  10  11  12  13  18  21  22  24  25  26  30 ## [20]  31  34  36  37  42  45  48  49  55  58  59  60  61  64  66  68  70  71  73 ## [39]  76  77  81  82  87  89  90  91  92  93  96  97  98 102 103 104 105 108 109 ## [58] 110 111 115 122 125 126 130 132 133 134 135 ##  ## $Fold2.Rep1 ##  [1]   1  14  15  16  17  19  20  23  27  28  29  32  33  35  38  39  40  41  43 ## [20]  44  46  47  50  51  52  53  54  56  57  62  63  65  67  69  72  74  75  78 ## [39]  79  80  83  84  85  86  88  94  95  99 100 101 106 107 112 113 114 116 117 ## [58] 118 119 120 121 123 124 127 128 129 131 136 137 ##  ## $Fold1.Rep2 ##  [1]   3   4   5   6   7   8  13  15  21  22  23  24  28  29  30  31  32  34  35 ## [20]  42  47  48  51  52  54  57  59  60  61  63  64  66  67  73  74  77  78  79 ## [39]  82  84  85  89  90  92  93  94  96  98  99 102 103 108 109 110 112 114 116 ## [58] 122 123 124 125 126 128 131 132 133 135 136 ##  ## $Fold2.Rep2 ##  [1]   1   2   9  10  11  12  14  16  17  18  19  20  25  26  27  33  36  37  38 ## [20]  39  40  41  43  44  45  46  49  50  53  55  56  58  62  65  68  69  70  71 ## [39]  72  75  76  80  81  83  86  87  88  91  95  97 100 101 104 105 106 107 111 ## [58] 113 115 117 118 119 120 121 127 129 130 134 137 ##  ## $Fold1.Rep3 ##  [1]   2   5   6   8   9  11  13  14  17  19  20  21  24  26  27  30  31  32  34 ## [20]  36  37  38  41  42  44  46  47  48  52  53  54  58  59  60  62  65  66  69 ## [39]  70  71  72  75  76  77  78  80  84  85  86  88  89  90  91  92  93  94  99 ## [58] 100 103 104 109 111 112 113 121 126 127 128 129 ##  ## $Fold2.Rep3 ##  [1]   1   3   4   7  10  12  15  16  18  22  23  25  28  29  33  35  39  40  43 ## [20]  45  49  50  51  55  56  57  61  63  64  67  68  73  74  79  81  82  83  87 ## [39]  95  96  97  98 101 102 105 106 107 108 110 114 115 116 117 118 119 120 122 ## [58] 123 124 125 130 131 132 133 134 135 136 137 ##  ## $Fold1.Rep4 ##  [1]   1   2   5   8  10  14  16  17  19  22  23  24  25  27  28  31  33  34  37 ## [20]  39  40  42  43  44  48  53  54  56  58  61  65  67  68  70  71  72  74  77 ## [39]  78  80  81  82  83  84  85  87  89  91  93  95  97 102 104 111 113 119 120 ## [58] 122 123 125 126 127 129 131 132 133 134 135 ##  ## $Fold2.Rep4 ##  [1]   3   4   6   7   9  11  12  13  15  18  20  21  26  29  30  32  35  36  38 ## [20]  41  45  46  47  49  50  51  52  55  57  59  60  62  63  64  66  69  73  75 ## [39]  76  79  86  88  90  92  94  96  98  99 100 101 103 105 106 107 108 109 110 ## [58] 112 114 115 116 117 118 121 124 128 130 136 137 ##  ## $Fold1.Rep5 ##  [1]   2   3   5   6   7   8   9  10  11  13  14  15  18  19  21  23  29  31  33 ## [20]  35  37  40  42  43  45  46  47  51  52  54  56  57  60  61  62  66  67  68 ## [39]  69  72  76  79  81  86  87  93  94  97 100 101 102 103 106 107 108 111 115 ## [58] 116 117 118 119 123 126 127 128 129 132 134 ##  ## $Fold2.Rep5 ##  [1]   1   4  12  16  17  20  22  24  25  26  27  28  30  32  34  36  38  39  41 ## [20]  44  48  49  50  53  55  58  59  63  64  65  70  71  73  74  75  77  78  80 ## [39]  82  83  84  85  88  89  90  91  92  95  96  98  99 104 105 109 110 112 113 ## [58] 114 120 121 122 124 125 130 131 133 135 136 137"},{"path":"https://sydneybiox.github.io/BenchHub/articles/v01_intro_trio.html","id":"conclusion","dir":"Articles","previous_headings":"","what":"Conclusion","title":"1 Introduction to the Trio Class","text":"vignette, introduced Trio class demonstrated create Trio object using curated datasets, source ID, loading object directly. also showed add metrics auxiliary data Trio object evaluate performance different methods using metrics auxiliary data. hope vignette helps get started Trio conduct benchmarking studies effectively.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/articles/v01_intro_trio.html","id":"session-info","dir":"Articles","previous_headings":"","what":"Session Info","title":"1 Introduction to the Trio Class","text":"","code":"sessionInfo() ## R version 4.4.3 (2025-02-28) ## Platform: x86_64-pc-linux-gnu ## Running under: Ubuntu 24.04.2 LTS ##  ## Matrix products: default ## BLAS:   /usr/lib/x86_64-linux-gnu/openblas-pthread/libblas.so.3  ## LAPACK: /usr/lib/x86_64-linux-gnu/openblas-pthread/libopenblasp-r0.3.26.so;  LAPACK version 3.12.0 ##  ## locale: ##  [1] LC_CTYPE=C.UTF-8       LC_NUMERIC=C           LC_TIME=C.UTF-8        ##  [4] LC_COLLATE=C.UTF-8     LC_MONETARY=C.UTF-8    LC_MESSAGES=C.UTF-8    ##  [7] LC_PAPER=C.UTF-8       LC_NAME=C              LC_ADDRESS=C           ## [10] LC_TELEPHONE=C         LC_MEASUREMENT=C.UTF-8 LC_IDENTIFICATION=C    ##  ## time zone: UTC ## tzcode source: system (glibc) ##  ## attached base packages: ## [1] stats4    stats     graphics  grDevices utils     datasets  methods   ## [8] base      ##  ## other attached packages: ##  [1] EnsDb.Hsapiens.v86_2.99.0 ensembldb_2.30.0          ##  [3] AnnotationFilter_1.30.0   GenomicFeatures_1.58.0    ##  [5] GenomicRanges_1.58.0      GenomeInfoDb_1.42.3       ##  [7] DO.db_2.9                 AnnotationDbi_1.68.0      ##  [9] IRanges_2.40.1            S4Vectors_0.44.0          ## [11] Biobase_2.66.0            BiocGenerics_0.52.0       ## [13] DOSE_4.0.0                clusterProfiler_4.14.6    ## [15] BenchHub_0.0.1            ggplot2_3.5.1             ## [17] BiocStyle_2.34.0          ##  ## loaded via a namespace (and not attached): ##   [1] splines_4.4.3               BiocIO_1.16.0               ##   [3] polspline_1.1.25            bitops_1.0-9                ##   [5] ggplotify_0.1.2             tibble_3.2.1                ##   [7] R.oo_1.27.0                 cellranger_1.1.0            ##   [9] datawizard_1.0.1            XML_3.99-0.18               ##  [11] rpart_4.1.24                httr2_1.1.1                 ##  [13] lifecycle_1.0.4             vroom_1.6.5                 ##  [15] lattice_0.22-6              MASS_7.3-64                 ##  [17] insight_1.1.0               backports_1.5.0             ##  [19] magrittr_2.0.3              Hmisc_5.2-2                 ##  [21] sass_0.4.9                  rmarkdown_2.29              ##  [23] jquerylib_0.1.4             yaml_2.3.10                 ##  [25] ggtangle_0.0.6              cowplot_1.1.3               ##  [27] DBI_1.2.3                   RColorBrewer_1.1-3          ##  [29] abind_1.4-8                 multcomp_1.4-28             ##  [31] zlibbioc_1.52.0             purrr_1.0.4                 ##  [33] R.utils_2.13.0              RCurl_1.98-1.16             ##  [35] yulab.utils_0.2.0           nnet_7.3-20                 ##  [37] TH.data_1.1-3               rappdirs_0.3.3              ##  [39] sandwich_3.1-1              GenomeInfoDbData_1.2.13     ##  [41] enrichplot_1.26.6           ggrepel_0.9.6               ##  [43] tidytree_0.4.6              MatrixModels_0.5-3          ##  [45] performance_0.13.0          pkgdown_2.1.1               ##  [47] DelayedArray_0.32.0         codetools_0.2-20            ##  [49] tidyselect_1.2.1            aplot_0.2.5                 ##  [51] UCSC.utils_1.2.0            farver_2.1.2                ##  [53] matrixStats_1.5.0           base64enc_0.1-3             ##  [55] googledrive_2.1.1           GenomicAlignments_1.42.0    ##  [57] jsonlite_1.9.1              Formula_1.2-5               ##  [59] survival_3.8-3              systemfonts_1.2.1           ##  [61] tools_4.4.3                 treeio_1.30.0               ##  [63] ragg_1.3.3                  Rcpp_1.0.14                 ##  [65] glue_1.8.0                  SparseArray_1.6.2           ##  [67] gridExtra_2.3               xfun_0.51                   ##  [69] MatrixGenerics_1.18.1       qvalue_2.38.0               ##  [71] dplyr_1.1.4                 withr_3.0.2                 ##  [73] BiocManager_1.30.25         fastmap_1.2.0               ##  [75] SparseM_1.84-2              digest_0.6.37               ##  [77] R6_2.6.1                    gridGraphics_0.5-1          ##  [79] textshaping_1.0.0           colorspace_2.1-1            ##  [81] GO.db_3.20.0                RSQLite_2.3.9               ##  [83] R.methodsS3_1.8.2           googlesheets4_1.1.1         ##  [85] tidyr_1.3.1                 generics_0.1.3              ##  [87] ggsci_3.2.0                 data.table_1.17.0           ##  [89] rtracklayer_1.66.0          S4Arrays_1.6.0              ##  [91] httr_1.4.7                  htmlwidgets_1.6.4           ##  [93] parameters_0.24.2           pkgconfig_2.0.3             ##  [95] gtable_0.3.6                blob_1.2.4                  ##  [97] XVector_0.46.0              htmltools_0.5.8.1           ##  [99] bookdown_0.42               fgsea_1.32.2                ## [101] ProtGenerics_1.38.0         scales_1.3.0                ## [103] png_0.1-8                   ggfun_0.1.8                 ## [105] splitTools_1.0.1            knitr_1.49                  ## [107] rstudioapi_0.17.1           tzdb_0.4.0                  ## [109] rjson_0.2.23                reshape2_1.4.4              ## [111] checkmate_2.3.2             nlme_3.1-167                ## [113] curl_6.2.1                  survAUC_1.3-0               ## [115] ggcorrplot_0.1.4.1          cachem_1.1.0                ## [117] zoo_1.8-13                  stringr_1.5.1               ## [119] parallel_4.4.3              foreign_0.8-88              ## [121] restfulr_0.0.15             desc_1.4.3                  ## [123] pillar_1.10.1               grid_4.4.3                  ## [125] vctrs_0.6.5                 cluster_2.1.8               ## [127] htmlTable_2.4.3             evaluate_1.0.3              ## [129] readr_2.1.5                 Rsamtools_2.22.0            ## [131] mvtnorm_1.3-3               cli_3.6.4                   ## [133] compiler_4.4.3              rlang_1.1.5                 ## [135] crayon_1.5.3                rms_7.0-0                   ## [137] plyr_1.8.9                  fs_1.6.5                    ## [139] stringi_1.8.4               BiocParallel_1.40.0         ## [141] munsell_0.5.1               Biostrings_2.74.1           ## [143] lazyeval_0.2.2              bayestestR_0.15.2           ## [145] GOSemSim_2.32.0             quantreg_6.1                ## [147] Matrix_1.7-2                hms_1.1.3                   ## [149] patchwork_1.3.0             bit64_4.6.0-1               ## [151] KEGGREST_1.46.0             SummarizedExperiment_1.36.0 ## [153] dotwhisker_0.8.3            gargle_1.5.2                ## [155] igraph_2.1.4                broom_1.0.7                 ## [157] memoise_2.0.1               bslib_0.9.0                 ## [159] ggtree_3.14.0               fastmatch_1.1-6             ## [161] bit_4.6.0                   ggstance_0.3.7              ## [163] ape_5.8-1                   gson_0.1.0"},{"path":"https://sydneybiox.github.io/BenchHub/articles/v02_Evaluation_using_Trio.html","id":"import-microbiome-data","dir":"Articles","previous_headings":"","what":"Import microbiome data","title":"2 Evaluation using TrioR","text":"TrioR can take datasets provided users. demonstrate, ability take user-provided datasets, ’ll using microbiome dataset called Lubomski obtained PD16Sdata package. following code import Lubomksi data R. lubomski_microbiome_data.Rdata contains two data objects: x lubomPD. x 575 1192 matrix containing abundance 1192 microbial taxa 575 samples. lubom_pd factor vector binary patient classes 575 samples 1 represents PD 0 represents HC. task ’ll evaluating using TrioR binary classification task sample either Parkinson’s Disease (PD) patient Healthy Control (HC). data ready inputted TrioR, can load TrioR.","code":"# import the microbiome data data(\"lubomski_microbiome_data\", package = \"BenchHub\")  # check the dimension of the microbiome matrix dim(x) ## [1]  575 1192 # check the length of the patient status length(lubomPD) ## [1] 575"},{"path":"https://sydneybiox.github.io/BenchHub/articles/v02_Evaluation_using_Trio.html","id":"initialise-a-trior-object","dir":"Articles","previous_headings":"","what":"Initialise a TrioR object","title":"2 Evaluation using TrioR","text":"initialise TrioR object, use new() method. Next use microbiome data illustrate two examples, 1) evaluation cross validation, 2) evaluation without cross validation.","code":"trio <- Trio$new(data = x, datasetID = \"lubomski_microbiome\")"},{"path":"https://sydneybiox.github.io/BenchHub/articles/v02_Evaluation_using_Trio.html","id":"cross-validation---using-the-trior-split-function","dir":"Articles","previous_headings":"","what":"Cross validation - using the trioR split function","title":"2 Evaluation using TrioR","text":"example, show typical classification scenario classify patient status, need split data training testing set.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/articles/v02_Evaluation_using_Trio.html","id":"step-1-add-a-metric-to-it-using-trioaddmetric","dir":"Articles","previous_headings":"Cross validation - using the trioR split function","what":"Step 1: Add a metric to it using Trio$addMetric()","title":"2 Evaluation using TrioR","text":"Users can use existing evaluation functions specifying metric, can name evaluation metric specifying name. Since evaluation task classification task, chose balanced accuracy, using existing function bundled BenchHub, named Balanced Accuracy.","code":"# add a metric to the Trio object trio$addMetric(name = \"Balanced Accuracy\", metric = balAccMetric)"},{"path":"https://sydneybiox.github.io/BenchHub/articles/v02_Evaluation_using_Trio.html","id":"step-2-add-auxiliary-data-to-the-trior-object-using-trioaddauxdata","dir":"Articles","previous_headings":"Cross validation - using the trioR split function","what":"Step 2: Add auxiliary data to the TrioR object using Trio$addAuxData","title":"2 Evaluation using TrioR","text":"auxiliary data patient status, lubomPD vector extracted Lubomski data . Similar adding metric, users can name auxiliary data specifying name. Note users need specify evaluation metric used metrics argument, match evaluation metric added TrioR object. users want get evaluation metrics TrioR object, can use getMetrics function referring name auxData. Step 3: Obtain relevant data model. build model, following code extract data matrix patient status outcome TrioR object. Step 4: repeated cross-validation, split() function split y vector (.e., auxData) number folds repeats users want. case used n_fold = 2 n_repeat = 5 (.e., 2-fold cross-validation 10 repeats). users can get cross-validation indices (cv_ind) sample, splitIndices. gives simple list element represents combination folds repeats sample. Step 5: Build classification model evaluate. can now use loop cross-validate evaluation results. Using cv_ind, user can subset training test data. example, build LASSO regression model classification model training data, make predictions test data. get prediction, pass pred vector TrioR ref name auxData (patient_status = pred). tells evaluate() function compare pred vector auxData patient_status stored TrioR object. computes balanced accuracy, metric specified. cross-validation, can visualise cross-validation results averaging results across folds within repeats.","code":"# add auxiliary data to the Trio object # name is the user-defined name, can be anything # auxData is the value of the auxiliary data # metric needs to be same name of the metric that has been added to the Trio object trio$addAuxData(   name = \"patient_status\", auxData = lubomPD, metrics = \"Balanced Accuracy\" ) # get the metric from the Trio object metrics <- trio$getMetrics(\"patient_status\") # get the gold standard from the Trio object x <- trio$data y <- trio$getAuxData(\"patient_status\") # get train and test indices trio$split(y = y, n_fold = 2, n_repeat = 5) cv_ind <- trio$splitIndices set.seed(1234)  result <- data.frame()  # loop through the 2 folds x 5 repeats = 10 runs for (i in seq_along(cv_ind)) {   train_id <- cv_ind[[i]]    x_train <- x[train_id, ]   x_test <- x[-train_id, ]   y_train <- y[train_id]   y_test <- y[-train_id]    #  find the best lambda for LASSO regression   cv_lasso <- cv.glmnet(as.matrix(x_train), y_train,     alpha = 1, family = \"binomial\"   )   lam <- cv_lasso$lambda.1se    # fit a model with the best lambda on training data   fit <- glmnet(x_train, y_train, alpha = 1, lambda = lam, family = \"binomial\")    # evaluate the model on test data   pred <- predict(fit, x_test, s = \"lambda.min\", type = \"class\")   pred <- as.factor(as.vector(pred))    # get the chosen evaluation metric from the Trio   eval_res <- trio$evaluate(     list(lasso = list(patient_status = pred)),     splitIndex = i   )    # keep track of the repeat and fold information   eval_res$track <- names(cv_ind)[[i]]   result <- rbind(result, eval_res) } result$fold <- unlist(lapply(strsplit(result$track, \".\", fixed = TRUE), `[`, 1))  result$repeats <- unlist(lapply(strsplit(result$track, \".\", fixed = TRUE), `[`, 2))  result <- result %>%   dplyr::group_by(datasetID, method, auxData, metric, repeats) %>%   dplyr::summarize(result = mean(result)) ## `summarise()` has grouped output by 'datasetID', 'method', 'auxData', 'metric'. ## You can override using the `.groups` argument. # visualise the result boxplot(result$result) # look at the format of the result output result ## # A tibble: 5 × 6 ## # Groups:   datasetID, method, auxData, metric [1] ##   datasetID           method auxData        metric            repeats result ##   <chr>               <chr>  <chr>          <chr>             <chr>    <dbl> ## 1 lubomski_microbiome lasso  patient_status Balanced Accuracy Rep1     0.735 ## 2 lubomski_microbiome lasso  patient_status Balanced Accuracy Rep2     0.716 ## 3 lubomski_microbiome lasso  patient_status Balanced Accuracy Rep3     0.770 ## 4 lubomski_microbiome lasso  patient_status Balanced Accuracy Rep4     0.711 ## 5 lubomski_microbiome lasso  patient_status Balanced Accuracy Rep5     0.717"},{"path":"https://sydneybiox.github.io/BenchHub/articles/v02_Evaluation_using_Trio.html","id":"without-cross-validation","dir":"Articles","previous_headings":"","what":"Without cross validation","title":"2 Evaluation using TrioR","text":"example, show simpler case without cross validation, prediction want compare ground truth directly. example, may simulated single-cell count matrix want compare experimental count matrix various attributes. , use microbiome dataset demonstrate case. Step 1: Simulate matrix size microbiome data using negative binomial. Step 2: Define function calculate sparsity given matrix. Step 3: Define metric compare difference two values. Step 4: Evaluate difference sparsity microbiome data simulated data. evaluation result, see 0.32 difference sparsity microbiome data data simulated negative binomial.","code":"set.seed(1)  # generate a simulated matrix sim <- rnbinom(nrow(x) * ncol(x), size = 1, mu = 1) sim <- Matrix(sim, nrow = nrow(x), ncol = ncol(x))  # function that calculate the sparsity of a matrix calc_sparsity <- function(data) {   sparsity <- sum(data == 0) / length(data)   return(sparsity) }   # metric that compare the difference of two values calc_diff <- function(pred, gt) {   return(gt - pred) } # add metric that we just defined trio$addMetric(name = \"Difference\", metric = calc_diff)  # calculate the sparsity of the data, and then input into the auxillary data trio$addAuxData(name = \"Sparsity\", auxData = calc_sparsity(x), metrics = \"Difference\")   # because we used negative binomial to simulate a matrix # we will name the method as \"negative binomial\" # then calculate the sparsity of the simulated matrix and compare with the Sparsity auxiliary data eval_res <- trio$evaluate(   list(negative_binomial = list(Sparsity = calc_sparsity(sim))) )  eval_res ## # A tibble: 1 × 5 ##   datasetID           method            auxData  metric     result ##   <chr>               <chr>             <chr>    <chr>       <dbl> ## 1 lubomski_microbiome negative_binomial Sparsity Difference  0.323"},{"path":"https://sydneybiox.github.io/BenchHub/articles/v02_Evaluation_using_Trio.html","id":"importing-result-to-benchmarkinsights","dir":"Articles","previous_headings":"","what":"Importing result to BenchmarkInsights","title":"2 Evaluation using TrioR","text":"result dataframe obtained Trio evaluation can passed BenchmarkInsights subsequent visualisation. BenchmarkInsights another structure BenchHub provide list functions analyse visualise benchmarking results multiple perspectives. Note, make result dataframe compatible BenchmarkInsights, please make sure dataframe format shown , column names “datasetID”, “method”, “auxData”, “metric” , “result”, one row result. Please see Vignette xxxxx details visualisations functions BenchmarkInsights.","code":"# in the with cross validation result, we need to average the results from multiple repeats to give one value result <- result %>%   dplyr::group_by(datasetID, method, auxData, metric) %>%   dplyr::summarize(result = mean(result)) ## `summarise()` has grouped output by 'datasetID', 'method', 'auxData'. You can ## override using the `.groups` argument. result <- rbind(result, eval_res) result ## # A tibble: 2 × 5 ## # Groups:   datasetID, method, auxData [2] ##   datasetID           method            auxData        metric            result ##   <chr>               <chr>             <chr>          <chr>              <dbl> ## 1 lubomski_microbiome lasso             patient_status Balanced Accuracy  0.730 ## 2 lubomski_microbiome negative_binomial Sparsity       Difference         0.323"},{"path":"https://sydneybiox.github.io/BenchHub/articles/v02_Evaluation_using_Trio.html","id":"session-info","dir":"Articles","previous_headings":"","what":"Session Info","title":"2 Evaluation using TrioR","text":"","code":"sessionInfo() ## R version 4.4.3 (2025-02-28) ## Platform: x86_64-pc-linux-gnu ## Running under: Ubuntu 24.04.2 LTS ##  ## Matrix products: default ## BLAS:   /usr/lib/x86_64-linux-gnu/openblas-pthread/libblas.so.3  ## LAPACK: /usr/lib/x86_64-linux-gnu/openblas-pthread/libopenblasp-r0.3.26.so;  LAPACK version 3.12.0 ##  ## locale: ##  [1] LC_CTYPE=C.UTF-8       LC_NUMERIC=C           LC_TIME=C.UTF-8        ##  [4] LC_COLLATE=C.UTF-8     LC_MONETARY=C.UTF-8    LC_MESSAGES=C.UTF-8    ##  [7] LC_PAPER=C.UTF-8       LC_NAME=C              LC_ADDRESS=C           ## [10] LC_TELEPHONE=C         LC_MEASUREMENT=C.UTF-8 LC_IDENTIFICATION=C    ##  ## time zone: UTC ## tzcode source: system (glibc) ##  ## attached base packages: ## [1] stats     graphics  grDevices utils     datasets  methods   base      ##  ## other attached packages: ##  [1] glmnet_4.1-8    Matrix_1.7-2    lubridate_1.9.4 forcats_1.0.0   ##  [5] stringr_1.5.1   dplyr_1.1.4     purrr_1.0.4     readr_2.1.5     ##  [9] tidyr_1.3.1     tibble_3.2.1    tidyverse_2.0.0 BenchHub_0.0.1  ## [13] ggplot2_3.5.1   ##  ## loaded via a namespace (and not attached): ##  [1] gridExtra_2.3       sandwich_3.1-1      rlang_1.1.5         ##  [4] magrittr_2.0.3      multcomp_1.4-28     polspline_1.1.25    ##  [7] compiler_4.4.3      survAUC_1.3-0       systemfonts_1.2.1   ## [10] vctrs_0.6.5         reshape2_1.4.4      quantreg_6.1        ## [13] shape_1.4.6.1       pkgconfig_2.0.3     fastmap_1.2.0       ## [16] backports_1.5.0     utf8_1.2.4          ggstance_0.3.7      ## [19] rmarkdown_2.29      tzdb_0.4.0          ragg_1.3.3          ## [22] MatrixModels_0.5-3  xfun_0.51           cachem_1.1.0        ## [25] jsonlite_1.9.1      broom_1.0.7         cluster_2.1.8       ## [28] R6_2.6.1            bslib_0.9.0         stringi_1.8.4       ## [31] rpart_4.1.24        jquerylib_0.1.4     cellranger_1.1.0    ## [34] iterators_1.0.14    Rcpp_1.0.14         knitr_1.49          ## [37] zoo_1.8-13          base64enc_0.1-3     parameters_0.24.2   ## [40] timechange_0.3.0    splines_4.4.3       nnet_7.3-20         ## [43] tidyselect_1.2.1    rstudioapi_0.17.1   yaml_2.3.10         ## [46] codetools_0.2-20    curl_6.2.1          lattice_0.22-6      ## [49] plyr_1.8.9          withr_3.0.2         bayestestR_0.15.2   ## [52] evaluate_1.0.3      foreign_0.8-88      desc_1.4.3          ## [55] survival_3.8-3      pillar_1.10.1       foreach_1.5.2       ## [58] checkmate_2.3.2     insight_1.1.0       generics_0.1.3      ## [61] hms_1.1.3           munsell_0.5.1       scales_1.3.0        ## [64] glue_1.8.0          rms_7.0-0           Hmisc_5.2-2         ## [67] tools_4.4.3         data.table_1.17.0   SparseM_1.84-2      ## [70] fs_1.6.5            mvtnorm_1.3-3       grid_4.4.3          ## [73] datawizard_1.0.1    colorspace_2.1-1    nlme_3.1-167        ## [76] googlesheets4_1.1.1 patchwork_1.3.0     performance_0.13.0  ## [79] htmlTable_2.4.3     googledrive_2.1.1   splitTools_1.0.1    ## [82] Formula_1.2-5       cli_3.6.4           textshaping_1.0.0   ## [85] gargle_1.5.2        gtable_0.3.6        ggcorrplot_0.1.4.1  ## [88] ggsci_3.2.0         sass_0.4.9          digest_0.6.37       ## [91] ggrepel_0.9.6       TH.data_1.1-3       htmlwidgets_1.6.4   ## [94] farver_2.1.2        htmltools_0.5.8.1   pkgdown_2.1.1       ## [97] lifecycle_1.0.4     dotwhisker_0.8.3    MASS_7.3-64"},{"path":"https://sydneybiox.github.io/BenchHub/articles/v03_intro_bmi.html","id":"motivation","dir":"Articles","previous_headings":"","what":"Motivation","title":"Introduction of benchmarkInsight class","text":"BenchHub—R ecosystem make benchmarking easier. organizes evaluation metrics, gold standards(Auxiliary Data), even provides built-visualization tools help interpret results. BenchHub, researchers can quickly compare new methods, gain insights, actually trust benchmarking studies. vignette, going introduce benchmarkInsights class.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/articles/v03_intro_bmi.html","id":"creating-benchmarkinsights-class","dir":"Articles","previous_headings":"","what":"Creating benchmarkInsights class","title":"Introduction of benchmarkInsight class","text":"benchmarkInsight objects can created using corresponding constructor. example, benchmark result formatted dataframe, can create benchmarkInsight object follows. dataframe includes fixed name columns: datasetID, method, auxData, metric, result. use benchmark result SpatialSimBench create new object. benchmarkInsight object can instantiated using respective constructors. example, benchmark result stored dataframe, can create Trio object follows. dataframe must include following fixed columns: datasetID, method, auxData, metric, result. , demonstrate using benchmark results SpatialSimBench initialize new object. use trio$evaluation(), output automatically formatted required dataframe. However, use benchmark evaluation results, ensure adhere expected format. additional evaluation result, can use addevalSummary(). example: add additional metadata method, can use addMetadata(). example:","code":"result_path <- system.file(\"extdata\", \"spatialsimbench_result.csv\", package = \"BenchHub\") spatialsimbench_result <- read_csv(result_path) glimpse(spatialsimbench_result) ## Rows: 3,861 ## Columns: 5 ## $ datasetID <chr> \"BREAST\", \"HOSTEOSARCOMA\", \"HPROSTATE\", \"MBRAIN\", \"MCATUMOR\"… ## $ method    <chr> \"scDesign2\", \"scDesign2\", \"scDesign2\", \"scDesign2\", \"scDesig… ## $ auxData   <chr> \"scaledVar\", \"scaledVar\", \"scaledVar\", \"scaledVar\", \"scaledV… ## $ metric    <chr> \"KDEstat\", \"KDEstat\", \"KDEstat\", \"KDEstat\", \"KDEstat\", \"KDEs… ## $ result    <dbl> -0.18447837, 3.33680301, 6.95418978, 0.62077112, 0.34212005,… bmi <- benchmarkInsights$new(spatialsimbench_result) bmi ## <benchmarkInsights> ##   Public: ##     addevalSummary: function (additional_evalResult)  ##     addMetadata: function (metadata)  ##     clone: function (deep = FALSE)  ##     evalSummary: spec_tbl_df, tbl_df, tbl, data.frame ##     getBoxplot: function (evalResult, metricVariable, auxDataVariable)  ##     getCorplot: function (evalResult, input_type)  ##     getForestplot: function (evalResult, input_group, input_model)  ##     getHeatmap: function (evalSummary)  ##     getLineplot: function (evalResult, order = NULL, metricVariable)  ##     getScatterplot: function (evalResult, variables)  ##     initialize: function (evalResult = NULL)  ##     metadata: NULL add_result <- data.frame(   datasetID = rep(\"BREAST\", 13),   method = c(\"scDesign2\", \"scDesign3_gau\", \"scDesign3_nb\", \"scDesign3_poi\",               \"SPARsim\", \"splatter\", \"SRTsim\", \"symsim\", \"zinbwave\",               \"scDesign3_gau(rf)\", \"scDesign3_nb(rf)\", \"scDesign3_poi(rf)\", \"SRTsim(rf)\"),   auxData = rep(\"svg\", 13),   metric = rep(\"recall\", 13),   result = c(0.921940928, 0.957805907, 0.964135021, 0.989451477, 0.774261603,               0.890295359, 0.985232068, 0.067510549, 0.888185654,               0.957805907, 0.964135021, 0.989451477, 0.985232068),   stringsAsFactors = FALSE )  bmi$addevalSummary(add_result) metadata_srtsim <- data.frame(   method = \"SRTsim\",   year = 2023,   packageVersion = \"0.99.6\",   parameterSetting = \"default\",   spatialInfoReq = \"No\",   DOI = \"10.1186/s13059-023-02879-z\",   stringsAsFactors = FALSE   )  bmi$addMetadata(metadata_srtsim)"},{"path":[]},{"path":"https://sydneybiox.github.io/BenchHub/articles/v03_intro_bmi.html","id":"available-plot","dir":"Articles","previous_headings":"Visualization","what":"Available plot","title":"Introduction of benchmarkInsight class","text":"getHeatmap(evalReuslt): Creates heatmap evaluation summary averaging results across datasets. evalResult: dataframe containing evaluation summary. Note: heatmap, averages results across datasets. getCorplot(evalReuslt, input_type): Creates correlation plot based provided evaluation summary. evalResult: dataframe containing evaluation summary. input_type: either “auxData”, “metric”, “method”. getBoxplot(evalReuslt): Creates boxplot based provided evaluation summary. evalReuslt: dataframe containing evaluation summary. input_type: either “auxData”, “metric”, “method”. getForestplot(evalReuslt, input_group, input_model): Create forest plot using linear models based comparison groups provided evaluation summary. evalReuslt: dataframe containing evaluation summary. input_group: string specifying grouping variable (“datasetID”, “method”, “auxData” allowed). input_model: string specifying model variable (“datasetID”, “method”, “auxData” allowed). getScatterplot(evalReuslt, variables): scatter plot auxData, two methodd metrics. evalReuslt: dataframe containing evaluation summary, include two different metrics, auxData variables: character vector length two specifying metric names used x y axes. getLineplot(evalReuslt, order): Creates line plot given x y variables, optional grouping fixed x order. evalReuslt: dataframe containing evaluation summary. order: optional vector specifying order x-axis values.","code":""},{"path":[]},{"path":"https://sydneybiox.github.io/BenchHub/articles/v03_intro_bmi.html","id":"case-study-what-is-the-overview-of-summary","dir":"Articles","previous_headings":"Visualization > Interpretation benchmark result","what":"Case Study: What is the overview of summary?","title":"Introduction of benchmarkInsight class","text":"get high-level view method performance, use heatmap summarize evaluation results across datasets. helps identify overall trends, making easier compare methods performance differences.","code":"bmi$getHeatmap(bmi$evalSummary)"},{"path":"https://sydneybiox.github.io/BenchHub/articles/v03_intro_bmi.html","id":"case-study-what-is-the-correlation-between-auxdatametricmethod","dir":"Articles","previous_headings":"Visualization > Interpretation benchmark result","what":"Case Study: What is the correlation between auxData/metric/method?","title":"Introduction of benchmarkInsight class","text":"understand relationships different evaluation factors, use correlation plot examine auxData, metrics, methods interrelated. helps identify patterns, redundancies, dependencies among evaluation components.  investigate relationship two specific metrics, use scatter plot. visualization helps assess well two metrics align diverge across different methods, providing insights trade-offs performance consistency.","code":"bmi$getCorplot(bmi$evalSummary, \"method\") bmi$getScatterplot(bmi$evalSummary, c(\"recall\",\"precision\"))"},{"path":"https://sydneybiox.github.io/BenchHub/articles/v03_intro_bmi.html","id":"case-study-what-is-the-time-and-memory-trend","dir":"Articles","previous_headings":"Visualization > Interpretation benchmark result","what":"Case Study: What is the time and memory trend?","title":"Introduction of benchmarkInsight class","text":"evaluate scalability different methods, use line plot visualize trends computational time memory usage across different conditions. helps identify methods perform data complexity increases, revealing potential efficiency trade-offs.","code":"bmi$getLineplot(bmi$evalSummary, metricVariable = \"memory\")"},{"path":"https://sydneybiox.github.io/BenchHub/articles/v03_intro_bmi.html","id":"case-study-which-metric-is-most-effective-on-the-method","dir":"Articles","previous_headings":"Visualization > Interpretation benchmark result","what":"Case Study: Which metric is most effective on the method?","title":"Introduction of benchmarkInsight class","text":"assess metrics strongest influence method performance, use forest plot visualize relationship metrics methods. allows us quantify compare impact different metrics, helping identify critical evaluation factors.","code":"bmi$getForestplot(bmi$evalSummary, \"metric\", \"method\")"},{"path":"https://sydneybiox.github.io/BenchHub/articles/v03_intro_bmi.html","id":"case-study-how-does-method-variability-differ-across-datasets-for-a-specific-metric","dir":"Articles","previous_headings":"Visualization > Interpretation benchmark result","what":"Case Study: How does method variability differ across datasets for a specific metric?","title":"Introduction of benchmarkInsight class","text":"examine consistency method across different datasets given metric, use boxplot. visualization helps assess variability method performance, highlighting robustness instability applied different datasets.","code":"bmi$getBoxplot(bmi$evalSummary, metricVariable = \"KDEstat\", auxDataVariable = \"scaledVar\")"},{"path":[]},{"path":"https://sydneybiox.github.io/BenchHub/articles/v03_intro_bmi.html","id":"session-info","dir":"Articles","previous_headings":"","what":"Session Info","title":"Introduction of benchmarkInsight class","text":"","code":"sessionInfo() ## R version 4.4.3 (2025-02-28) ## Platform: x86_64-pc-linux-gnu ## Running under: Ubuntu 24.04.2 LTS ##  ## Matrix products: default ## BLAS:   /usr/lib/x86_64-linux-gnu/openblas-pthread/libblas.so.3  ## LAPACK: /usr/lib/x86_64-linux-gnu/openblas-pthread/libopenblasp-r0.3.26.so;  LAPACK version 3.12.0 ##  ## locale: ##  [1] LC_CTYPE=C.UTF-8       LC_NUMERIC=C           LC_TIME=C.UTF-8        ##  [4] LC_COLLATE=C.UTF-8     LC_MONETARY=C.UTF-8    LC_MESSAGES=C.UTF-8    ##  [7] LC_PAPER=C.UTF-8       LC_NAME=C              LC_ADDRESS=C           ## [10] LC_TELEPHONE=C         LC_MEASUREMENT=C.UTF-8 LC_IDENTIFICATION=C    ##  ## time zone: UTC ## tzcode source: system (glibc) ##  ## attached base packages: ## [1] stats     graphics  grDevices utils     datasets  methods   base      ##  ## other attached packages: ## [1] stringr_1.5.1    dplyr_1.1.4      readr_2.1.5      BenchHub_0.0.1   ## [5] ggplot2_3.5.1    BiocStyle_2.34.0 ##  ## loaded via a namespace (and not attached): ##   [1] Rdpack_2.6.2        gridExtra_2.3       sandwich_3.1-1      ##   [4] rlang_1.1.5         magrittr_2.0.3      multcomp_1.4-28     ##   [7] polspline_1.1.25    compiler_4.4.3      survAUC_1.3-0       ##  [10] systemfonts_1.2.1   vctrs_0.6.5         reshape2_1.4.4      ##  [13] quantreg_6.1        crayon_1.5.3        pkgconfig_2.0.3     ##  [16] fastmap_1.2.0       backports_1.5.0     labeling_0.4.3      ##  [19] ggstance_0.3.7      rmarkdown_2.29      tzdb_0.4.0          ##  [22] ragg_1.3.3          bit_4.6.0           MatrixModels_0.5-3  ##  [25] purrr_1.0.4         xfun_0.51           cachem_1.1.0        ##  [28] jsonlite_1.9.1      tweenr_2.0.3        parallel_4.4.3      ##  [31] broom_1.0.7         cluster_2.1.8       R6_2.6.1            ##  [34] RColorBrewer_1.1-3  bslib_0.9.0         stringi_1.8.4       ##  [37] rpart_4.1.24        jquerylib_0.1.4     cellranger_1.1.0    ##  [40] assertthat_0.2.1    Rcpp_1.0.14         bookdown_0.42       ##  [43] knitr_1.49          zoo_1.8-13          base64enc_0.1-3     ##  [46] parameters_0.24.2   Matrix_1.7-2        splines_4.4.3       ##  [49] nnet_7.3-20         tidyselect_1.2.1    rstudioapi_0.17.1   ##  [52] yaml_2.3.10         codetools_0.2-20    curl_6.2.1          ##  [55] lattice_0.22-6      tibble_3.2.1        plyr_1.8.9          ##  [58] withr_3.0.2         bayestestR_0.15.2   evaluate_1.0.3      ##  [61] foreign_0.8-88      desc_1.4.3          survival_3.8-3      ##  [64] polyclip_1.10-7     pillar_1.10.1       BiocManager_1.30.25 ##  [67] checkmate_2.3.2     insight_1.1.0       generics_0.1.3      ##  [70] vroom_1.6.5         hms_1.1.3           munsell_0.5.1       ##  [73] scales_1.3.0        glue_1.8.0          rms_7.0-0           ##  [76] Hmisc_5.2-2         tools_4.4.3         data.table_1.17.0   ##  [79] SparseM_1.84-2      fs_1.6.5            mvtnorm_1.3-3       ##  [82] cowplot_1.1.3       grid_4.4.3          tidyr_1.3.1         ##  [85] rbibutils_2.3       datawizard_1.0.1    colorspace_2.1-1    ##  [88] nlme_3.1-167        googlesheets4_1.1.1 patchwork_1.3.0     ##  [91] performance_0.13.0  ggforce_0.4.2       htmlTable_2.4.3     ##  [94] googledrive_2.1.1   splitTools_1.0.1    Formula_1.2-5       ##  [97] cli_3.6.4           textshaping_1.0.0   gargle_1.5.2        ## [100] funkyheatmap_0.5.1  gtable_0.3.6        ggcorrplot_0.1.4.1  ## [103] ggsci_3.2.0         sass_0.4.9          digest_0.6.37       ## [106] ggrepel_0.9.6       TH.data_1.1-3       htmlwidgets_1.6.4   ## [109] farver_2.1.2        htmltools_0.5.8.1   pkgdown_2.1.1       ## [112] lifecycle_1.0.4     bit64_4.6.0-1       dotwhisker_0.8.3    ## [115] MASS_7.3-64"},{"path":"https://sydneybiox.github.io/BenchHub/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Cabiria Liang. Author. Sanghyun Kim. Author. Nick Robertson. Author. Marni Torkel. Author. Yue Cao. Author. Dario Strbenac. Author. Jean Yang. Author. SOMS Maintainer. Author, maintainer.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Liang C, Kim S, Robertson N, Torkel M, Cao Y, Strbenac D, Yang J, Maintainer S (2025). BenchHub: Comprehensive Collection Curated Benchmarking Datasets Evaluation. R package version 0.0.1, https://sydneybiox.github.io/BenchHub/.","code":"@Manual{,   title = {BenchHub: Comprehensive Collection of Curated Benchmarking Datasets and their Evaluation},   author = {Cabiria Liang and Sanghyun Kim and Nick Robertson and Marni Torkel and Yue Cao and Dario Strbenac and Jean Yang and SOMS Maintainer},   year = {2025},   note = {R package version 0.0.1},   url = {https://sydneybiox.github.io/BenchHub/}, }"},{"path":[]},{"path":"https://sydneybiox.github.io/BenchHub/index.html","id":"installation-instruction","dir":"","previous_headings":"","what":"Installation instruction","title":"Comprehensive Collection of Curated Benchmarking Datasets and their Evaluation","text":"","code":"devtools::install_github(\"SydneyBioX/BenchHub\")"},{"path":"https://sydneybiox.github.io/BenchHub/index.html","id":"about","dir":"","previous_headings":"","what":"About","title":"Comprehensive Collection of Curated Benchmarking Datasets and their Evaluation","text":"BenchHub data storage framework facilitate living benchmarks. aims enhance reproducibility accessibility benchmarking studies making easier store, analyse share benchmarking data. two components currently BenchHub : - Trio: data structure consisting Dataset, Auxiliary Metric faciliate sharing benchmarking datasets within community. - BenchmarkInsight: data structure storing benchmarking results provides collection visualisations faciliate analysis benchmarking results.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/index.html","id":"trio","dir":"","previous_headings":"About","what":"Trio","title":"Comprehensive Collection of Curated Benchmarking Datasets and their Evaluation","text":"Trio built around three key components: Data: Data used methods generate output.Auxiliary Data: Metadata compare output methods, cell type, patient outcome, disease pathway.Metric: Evaluation metrics used compare output methods auxiliary data. Trio implemented R6 object fields store components.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/index.html","id":"benchmarkinsight","dir":"","previous_headings":"About","what":"BenchmarkInsight","title":"Comprehensive Collection of Curated Benchmarking Datasets and their Evaluation","text":"BenchmarkInsight serves visualisation analysis tool benchmarking results. contains multiple visualisation techniques help researchers analyse benchmarking results terms data, methods metrics. results evaluated using Trio, output can directly passed benchmarkInsight object. BenchmarkInsight currently supports following plot types.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/index.html","id":"vignettes","dir":"","previous_headings":"","what":"Vignettes","title":"Comprehensive Collection of Curated Benchmarking Datasets and their Evaluation","text":"provide comprehensive list vignettes every key step BenchHub. Please refer website see vignettes listed :","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/MCCmetric.html","id":null,"dir":"Reference","previous_headings":"","what":"Matthews Correlation Coefficient (MCC) Metric — MCCmetric","title":"Matthews Correlation Coefficient (MCC) Metric — MCCmetric","text":"Computes Matthews Correlation Coefficient (MCC) predictions.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/MCCmetric.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Matthews Correlation Coefficient (MCC) Metric — MCCmetric","text":"","code":"MCCmetric(auxData, predicted)"},{"path":"https://sydneybiox.github.io/BenchHub/reference/MCCmetric.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Matthews Correlation Coefficient (MCC) Metric — MCCmetric","text":"auxData true labels. predicted predicted labels.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/MCCmetric.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Matthews Correlation Coefficient (MCC) Metric — MCCmetric","text":"MCC.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/MCCmetric.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Matthews Correlation Coefficient (MCC) Metric — MCCmetric","text":"","code":"auxData <- factor(c(\"A\", \"B\", \"A\", \"B\")) predicted <- factor(c(\"A\", \"A\", \"A\", \"B\")) MCCmetric(auxData, predicted) #>         B  #> 0.5773503"},{"path":"https://sydneybiox.github.io/BenchHub/reference/MSEmetric.html","id":null,"dir":"Reference","previous_headings":"","what":"Mean Squared Error (MSE) Metric — MSEmetric","title":"Mean Squared Error (MSE) Metric — MSEmetric","text":"Computes mean squared error predictions.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/MSEmetric.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mean Squared Error (MSE) Metric — MSEmetric","text":"","code":"MSEmetric(auxData, predicted)"},{"path":"https://sydneybiox.github.io/BenchHub/reference/MSEmetric.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mean Squared Error (MSE) Metric — MSEmetric","text":"auxData true values. predicted predicted values.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/MSEmetric.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Mean Squared Error (MSE) Metric — MSEmetric","text":"mean squared error.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/MSEmetric.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Mean Squared Error (MSE) Metric — MSEmetric","text":"","code":"auxData <- c(1, 2, 3, 4) predicted <- c(1.1, 2.1, 2.9, 4.2) MSEmetric(auxData, predicted) #> [1] 0.0175"},{"path":"https://sydneybiox.github.io/BenchHub/reference/RecSys.html","id":null,"dir":"Reference","previous_headings":"","what":"A RecSys object — RecSys","title":"A RecSys object — RecSys","text":"object containing recommender system data-driven specific task.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/RecSys.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A RecSys object — RecSys","text":"RecSys object.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/RecSys.html","id":"public-fields","dir":"Reference","previous_headings":"","what":"Public fields","title":"A RecSys object — RecSys","text":"evalSummary evaluation summary stored dataframe, row compared identifier, column metric used evaluation task related information. metadata dataframe store metadata benchmark.","code":""},{"path":[]},{"path":"https://sydneybiox.github.io/BenchHub/reference/RecSys.html","id":"public-methods","dir":"Reference","previous_headings":"","what":"Public methods","title":"A RecSys object — RecSys","text":"RecSys$clone()","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/RecSys.html","id":"method-clone-","dir":"Reference","previous_headings":"","what":"Method clone()","title":"A RecSys object — RecSys","text":"objects class cloneable method.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/RecSys.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A RecSys object — RecSys","text":"","code":"RecSys$clone(deep = FALSE)"},{"path":"https://sydneybiox.github.io/BenchHub/reference/RecSys.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A RecSys object — RecSys","text":"deep Whether make deep clone.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/RecSys.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"A RecSys object — RecSys","text":"","code":"RecSys$new() #> <RecSys> #>   Public: #>     clone: function (deep = FALSE)  #>     evalSummary: NULL #>     metadata: NULL"},{"path":"https://sydneybiox.github.io/BenchHub/reference/Trio.html","id":null,"dir":"Reference","previous_headings":"","what":"A Trio object — Trio","title":"A Trio object — Trio","text":"object containing dataset methods evaluating analytical tasks ground truths dataset.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/Trio.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A Trio object — Trio","text":"Trio object","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/Trio.html","id":"public-fields","dir":"Reference","previous_headings":"","what":"Public fields","title":"A Trio object — Trio","text":"data data auxData auxiliary data data metrics metric evaluating tasks gold standards cachePath path data cache dataSource data repository data retrieved dataSourceID dataset ID dataSouce splitIndices Indices cross-validation splitSeed seed used generate split indices verbose Set verbosity Trio. Defaults FALSE.","code":""},{"path":[]},{"path":"https://sydneybiox.github.io/BenchHub/reference/Trio.html","id":"public-methods","dir":"Reference","previous_headings":"","what":"Public methods","title":"A Trio object — Trio","text":"Trio$new() Trio$addAuxData() Trio$addMetric() Trio$getMetrics() Trio$getAuxData() Trio$evaluate() Trio$split() Trio$print() Trio$clone()","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/Trio.html","id":"method-new-","dir":"Reference","previous_headings":"","what":"Method new()","title":"A Trio object — Trio","text":"Create Trio object","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/Trio.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A Trio object — Trio","text":"","code":"Trio$new(   datasetID = NULL,   data = NULL,   dataLoader = NULL,   cachePath = FALSE,   verbose = FALSE )"},{"path":"https://sydneybiox.github.io/BenchHub/reference/Trio.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A Trio object — Trio","text":"datasetID string specifying dataset, either name curated-trio-data format string form source:source_id. data object use Trio dataset. dataLoader custom loading fuction takes path downloaded file returns single dataset, ready used evaluation tasks. cachePath path data cache verbose Set verbosity Trio. Defaults FALSE.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/Trio.html","id":"method-addauxdata-","dir":"Reference","previous_headings":"","what":"Method addAuxData()","title":"A Trio object — Trio","text":"Add gold standard Trio.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/Trio.html","id":"usage-1","dir":"Reference","previous_headings":"","what":"Usage","title":"A Trio object — Trio","text":"","code":"Trio$addAuxData(name, auxData, metrics, args = NULL)"},{"path":"https://sydneybiox.github.io/BenchHub/reference/Trio.html","id":"arguments-1","dir":"Reference","previous_headings":"","what":"Arguments","title":"A Trio object — Trio","text":"name string specifying name gold standard. auxData auxiliary data. object compared function run data. metrics list one metrics names used campare gs input evaluate. args named list parameters values passed function.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/Trio.html","id":"method-addmetric-","dir":"Reference","previous_headings":"","what":"Method addMetric()","title":"A Trio object — Trio","text":"Add metric Trio.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/Trio.html","id":"usage-2","dir":"Reference","previous_headings":"","what":"Usage","title":"A Trio object — Trio","text":"","code":"Trio$addMetric(name, metric, args = NULL)"},{"path":"https://sydneybiox.github.io/BenchHub/reference/Trio.html","id":"arguments-2","dir":"Reference","previous_headings":"","what":"Arguments","title":"A Trio object — Trio","text":"name string specifying name metric. metric metric. function run input evaluate compare gold standard. form f(x, y, ...). x \"truth\" y output evaluated. Otherwise input wrapper function desired metric. args named list parameters values passed function.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/Trio.html","id":"method-getmetrics-","dir":"Reference","previous_headings":"","what":"Method getMetrics()","title":"A Trio object — Trio","text":"Get metrics gold standard name.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/Trio.html","id":"usage-3","dir":"Reference","previous_headings":"","what":"Usage","title":"A Trio object — Trio","text":"","code":"Trio$getMetrics(auxDataName)"},{"path":"https://sydneybiox.github.io/BenchHub/reference/Trio.html","id":"arguments-3","dir":"Reference","previous_headings":"","what":"Arguments","title":"A Trio object — Trio","text":"auxDataName string specifying name gold standard.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/Trio.html","id":"method-getauxdata-","dir":"Reference","previous_headings":"","what":"Method getAuxData()","title":"A Trio object — Trio","text":"Get auxiliary data name.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/Trio.html","id":"usage-4","dir":"Reference","previous_headings":"","what":"Usage","title":"A Trio object — Trio","text":"","code":"Trio$getAuxData(name)"},{"path":"https://sydneybiox.github.io/BenchHub/reference/Trio.html","id":"arguments-4","dir":"Reference","previous_headings":"","what":"Arguments","title":"A Trio object — Trio","text":"name string specifying name auxiliary data.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/Trio.html","id":"method-evaluate-","dir":"Reference","previous_headings":"","what":"Method evaluate()","title":"A Trio object — Trio","text":"Evalute gold standards","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/Trio.html","id":"usage-5","dir":"Reference","previous_headings":"","what":"Usage","title":"A Trio object — Trio","text":"","code":"Trio$evaluate(input, splitIndex = NULL)"},{"path":"https://sydneybiox.github.io/BenchHub/reference/Trio.html","id":"arguments-5","dir":"Reference","previous_headings":"","what":"Arguments","title":"A Trio object — Trio","text":"input named list objects evaluated gold standards. splitIndex optional index subsetting data evaluation using indices created split method.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/Trio.html","id":"method-split-","dir":"Reference","previous_headings":"","what":"Method split()","title":"A Trio object — Trio","text":"Create cross-validation indices.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/Trio.html","id":"usage-6","dir":"Reference","previous_headings":"","what":"Usage","title":"A Trio object — Trio","text":"","code":"Trio$split(   y,   n_fold = 5L,   n_repeat = 1L,   stratify = TRUE,   seed = NULL,   overwrite = FALSE )"},{"path":"https://sydneybiox.github.io/BenchHub/reference/Trio.html","id":"arguments-6","dir":"Reference","previous_headings":"","what":"Arguments","title":"A Trio object — Trio","text":"y variable use statified sampling. stratify false, vector length data. n_fold Number folds. Defaults 5L. n_repeat Number repeats. Defaults 1L. stratify TRUE, uses stratified sampling. Defaults TRUE. seed optional seed split generation. Defaults NULL. NULL, seed set current time. overwrite TRUE, overwrites current split. Defaults FALSE.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/Trio.html","id":"method-print-","dir":"Reference","previous_headings":"","what":"Method print()","title":"A Trio object — Trio","text":"Print method display key information Trio object.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/Trio.html","id":"usage-7","dir":"Reference","previous_headings":"","what":"Usage","title":"A Trio object — Trio","text":"","code":"Trio$print()"},{"path":"https://sydneybiox.github.io/BenchHub/reference/Trio.html","id":"method-clone-","dir":"Reference","previous_headings":"","what":"Method clone()","title":"A Trio object — Trio","text":"objects class cloneable method.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/Trio.html","id":"usage-8","dir":"Reference","previous_headings":"","what":"Usage","title":"A Trio object — Trio","text":"","code":"Trio$clone(deep = FALSE)"},{"path":"https://sydneybiox.github.io/BenchHub/reference/Trio.html","id":"arguments-7","dir":"Reference","previous_headings":"","what":"Arguments","title":"A Trio object — Trio","text":"deep Whether make deep clone.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/Trio.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"A Trio object — Trio","text":"","code":"trio <- Trio$new(\"figshare:26054188/47112109\", cachePath = tempdir())"},{"path":"https://sydneybiox.github.io/BenchHub/reference/balAccMetric.html","id":null,"dir":"Reference","previous_headings":"","what":"Balanced Accuracy Metric — balAccMetric","title":"Balanced Accuracy Metric — balAccMetric","text":"Computes balanced accuracy predictions.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/balAccMetric.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Balanced Accuracy Metric — balAccMetric","text":"","code":"balAccMetric(auxData, predicted)"},{"path":"https://sydneybiox.github.io/BenchHub/reference/balAccMetric.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Balanced Accuracy Metric — balAccMetric","text":"auxData true labels. predicted predicted labels.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/balAccMetric.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Balanced Accuracy Metric — balAccMetric","text":"balanced accuracy.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/balAccMetric.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Balanced Accuracy Metric — balAccMetric","text":"","code":"auxData <- factor(c(\"A\", \"B\", \"A\", \"B\")) predicted <- factor(c(\"A\", \"A\", \"A\", \"B\")) balAccMetric(auxData, predicted) #> [1] 0.75"},{"path":"https://sydneybiox.github.io/BenchHub/reference/balErrMetric.html","id":null,"dir":"Reference","previous_headings":"","what":"Balanced Error Metric — balErrMetric","title":"Balanced Error Metric — balErrMetric","text":"Computes balanced error predictions.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/balErrMetric.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Balanced Error Metric — balErrMetric","text":"","code":"balErrMetric(auxData, predicted)"},{"path":"https://sydneybiox.github.io/BenchHub/reference/balErrMetric.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Balanced Error Metric — balErrMetric","text":"auxData true labels. predicted predicted labels.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/balErrMetric.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Balanced Error Metric — balErrMetric","text":"balanced error.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/balErrMetric.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Balanced Error Metric — balErrMetric","text":"","code":"auxData <- factor(c(\"A\", \"B\", \"A\", \"B\")) predicted <- factor(c(\"A\", \"A\", \"A\", \"B\")) balErrMetric(auxData, predicted) #> [1] 0.25"},{"path":"https://sydneybiox.github.io/BenchHub/reference/beggCIndexMetric.html","id":null,"dir":"Reference","previous_headings":"","what":"Begg's C-Index Metric — beggCIndexMetric","title":"Begg's C-Index Metric — beggCIndexMetric","text":"Computes Begg's C-Index survival analysis.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/beggCIndexMetric.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Begg's C-Index Metric — beggCIndexMetric","text":"","code":"beggCIndexMetric(auxData, predicted)"},{"path":"https://sydneybiox.github.io/BenchHub/reference/beggCIndexMetric.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Begg's C-Index Metric — beggCIndexMetric","text":"auxData true survival times event indicators. predicted predicted survival times.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/beggCIndexMetric.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Begg's C-Index Metric — beggCIndexMetric","text":"Begg's C-Index.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/beggCIndexMetric.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Begg's C-Index Metric — beggCIndexMetric","text":"","code":"# More realistic training dataset (8 patients) auxData <- list(   survival::Surv(time = c(5, 10, 15, 20, 25, 30, 35, 40),    event = c(1, 1, 0, 1, 0, 1, 1, 0)),  # Training   survival::Surv(time = c(12, 18, 25, 32),    event = c(1, 0, 1, 0))  # Testing ) # Predicted risk scores predicted <- list(   c(0.5142118, 0.3902035, 0.9057381, 0.4469696,    0.8360043, 0.7375956, 0.8110551, 0.3881083),  # Training predictions   c(0.685169729, 0.003948339, 0.832916080, 0.007334147)  # Testing predictions ) beggCIndexMetric(auxData, predicted) #> [1] 0.7134731"},{"path":"https://sydneybiox.github.io/BenchHub/reference/benchmarkInsights.html","id":null,"dir":"Reference","previous_headings":"","what":"A benchmarkInsights object — benchmarkInsights","title":"A benchmarkInsights object — benchmarkInsights","text":"object containing benchmark result evaluating analytical tasks.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/benchmarkInsights.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A benchmarkInsights object — benchmarkInsights","text":"benchmarkInsights object.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/benchmarkInsights.html","id":"public-fields","dir":"Reference","previous_headings":"","what":"Public fields","title":"A benchmarkInsights object — benchmarkInsights","text":"evalSummary evaluation summary stored dataframe, row methodd identifier, column metric used evaluation task related information. metadata dataframe store metadata benchmark.","code":""},{"path":[]},{"path":"https://sydneybiox.github.io/BenchHub/reference/benchmarkInsights.html","id":"public-methods","dir":"Reference","previous_headings":"","what":"Public methods","title":"A benchmarkInsights object — benchmarkInsights","text":"benchmarkInsights$new() benchmarkInsights$addevalSummary() benchmarkInsights$addMetadata() benchmarkInsights$getHeatmap() benchmarkInsights$getLineplot() benchmarkInsights$getScatterplot() benchmarkInsights$getBoxplot() benchmarkInsights$getCorplot() benchmarkInsights$getForestplot() benchmarkInsights$clone()","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/benchmarkInsights.html","id":"method-new-","dir":"Reference","previous_headings":"","what":"Method new()","title":"A benchmarkInsights object — benchmarkInsights","text":"Create benchmarkInsights object","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/benchmarkInsights.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A benchmarkInsights object — benchmarkInsights","text":"","code":"benchmarkInsights$new(evalResult = NULL)"},{"path":"https://sydneybiox.github.io/BenchHub/reference/benchmarkInsights.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A benchmarkInsights object — benchmarkInsights","text":"evalResult dataframe containing initial evaluation results columns datasetID, auxData, metric, result.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/benchmarkInsights.html","id":"method-addevalsummary-","dir":"Reference","previous_headings":"","what":"Method addevalSummary()","title":"A benchmarkInsights object — benchmarkInsights","text":"Add additional evaluation summary existing evalSummary","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/benchmarkInsights.html","id":"usage-1","dir":"Reference","previous_headings":"","what":"Usage","title":"A benchmarkInsights object — benchmarkInsights","text":"","code":"benchmarkInsights$addevalSummary(additional_evalResult)"},{"path":"https://sydneybiox.github.io/BenchHub/reference/benchmarkInsights.html","id":"arguments-1","dir":"Reference","previous_headings":"","what":"Arguments","title":"A benchmarkInsights object — benchmarkInsights","text":"additional_evalResult dataframe containing additional evaluation results appended.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/benchmarkInsights.html","id":"method-addmetadata-","dir":"Reference","previous_headings":"","what":"Method addMetadata()","title":"A benchmarkInsights object — benchmarkInsights","text":"Add metadata benchmarkInsights object","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/benchmarkInsights.html","id":"usage-2","dir":"Reference","previous_headings":"","what":"Usage","title":"A benchmarkInsights object — benchmarkInsights","text":"","code":"benchmarkInsights$addMetadata(metadata)"},{"path":"https://sydneybiox.github.io/BenchHub/reference/benchmarkInsights.html","id":"arguments-2","dir":"Reference","previous_headings":"","what":"Arguments","title":"A benchmarkInsights object — benchmarkInsights","text":"metadata dataframe containing metadata information.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/benchmarkInsights.html","id":"method-getheatmap-","dir":"Reference","previous_headings":"","what":"Method getHeatmap()","title":"A benchmarkInsights object — benchmarkInsights","text":"Creates heatmap evaluation summary averaging results across datasets.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/benchmarkInsights.html","id":"usage-3","dir":"Reference","previous_headings":"","what":"Usage","title":"A benchmarkInsights object — benchmarkInsights","text":"","code":"benchmarkInsights$getHeatmap(evalSummary)"},{"path":"https://sydneybiox.github.io/BenchHub/reference/benchmarkInsights.html","id":"arguments-3","dir":"Reference","previous_headings":"","what":"Arguments","title":"A benchmarkInsights object — benchmarkInsights","text":"evalSummary dataframe containing evaluation summary.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/benchmarkInsights.html","id":"returns","dir":"Reference","previous_headings":"","what":"Returns","title":"A benchmarkInsights object — benchmarkInsights","text":"heatmap object.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/benchmarkInsights.html","id":"method-getlineplot-","dir":"Reference","previous_headings":"","what":"Method getLineplot()","title":"A benchmarkInsights object — benchmarkInsights","text":"Creates line plot given x y variables, optional grouping fixed x order.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/benchmarkInsights.html","id":"usage-4","dir":"Reference","previous_headings":"","what":"Usage","title":"A benchmarkInsights object — benchmarkInsights","text":"","code":"benchmarkInsights$getLineplot(evalResult, order = NULL, metricVariable)"},{"path":"https://sydneybiox.github.io/BenchHub/reference/benchmarkInsights.html","id":"arguments-4","dir":"Reference","previous_headings":"","what":"Arguments","title":"A benchmarkInsights object — benchmarkInsights","text":"evalResult subset evaluation summary. order optional vector specifying order x-axis values. metricVariable Specify subset value metric column.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/benchmarkInsights.html","id":"returns-1","dir":"Reference","previous_headings":"","what":"Returns","title":"A benchmarkInsights object — benchmarkInsights","text":"ggplot2 line plot object.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/benchmarkInsights.html","id":"method-getscatterplot-","dir":"Reference","previous_headings":"","what":"Method getScatterplot()","title":"A benchmarkInsights object — benchmarkInsights","text":"Creates scatter plot auxData, two methodd metrics.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/benchmarkInsights.html","id":"usage-5","dir":"Reference","previous_headings":"","what":"Usage","title":"A benchmarkInsights object — benchmarkInsights","text":"","code":"benchmarkInsights$getScatterplot(evalResult, variables)"},{"path":"https://sydneybiox.github.io/BenchHub/reference/benchmarkInsights.html","id":"arguments-5","dir":"Reference","previous_headings":"","what":"Arguments","title":"A benchmarkInsights object — benchmarkInsights","text":"evalResult subset evaluation summary, include two different metrics, auxData variables character vector length two specifying metric names used x y axes.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/benchmarkInsights.html","id":"returns-2","dir":"Reference","previous_headings":"","what":"Returns","title":"A benchmarkInsights object — benchmarkInsights","text":"ggplot2 line plot object.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/benchmarkInsights.html","id":"method-getboxplot-","dir":"Reference","previous_headings":"","what":"Method getBoxplot()","title":"A benchmarkInsights object — benchmarkInsights","text":"Creates boxplot plots mutiple auxData, different method, one metric.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/benchmarkInsights.html","id":"usage-6","dir":"Reference","previous_headings":"","what":"Usage","title":"A benchmarkInsights object — benchmarkInsights","text":"","code":"benchmarkInsights$getBoxplot(evalResult, metricVariable, auxDataVariable)"},{"path":"https://sydneybiox.github.io/BenchHub/reference/benchmarkInsights.html","id":"arguments-6","dir":"Reference","previous_headings":"","what":"Arguments","title":"A benchmarkInsights object — benchmarkInsights","text":"evalResult subset evaluation summary, include two different metrics, auxData . metricVariable Specify subset value metric column. auxDataVariable Specify subset value auxData column.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/benchmarkInsights.html","id":"returns-3","dir":"Reference","previous_headings":"","what":"Returns","title":"A benchmarkInsights object — benchmarkInsights","text":"ggplot2 line plot object.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/benchmarkInsights.html","id":"method-getcorplot-","dir":"Reference","previous_headings":"","what":"Method getCorplot()","title":"A benchmarkInsights object — benchmarkInsights","text":"Creates correlation plot based provided evaluation summary specified input type (either \"auxData\", \"metric\", \"method\"). correlation plot shows pairwise correlation results different categories (auxData, metric, method).","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/benchmarkInsights.html","id":"usage-7","dir":"Reference","previous_headings":"","what":"Usage","title":"A benchmarkInsights object — benchmarkInsights","text":"","code":"benchmarkInsights$getCorplot(evalResult, input_type)"},{"path":"https://sydneybiox.github.io/BenchHub/reference/benchmarkInsights.html","id":"arguments-7","dir":"Reference","previous_headings":"","what":"Arguments","title":"A benchmarkInsights object — benchmarkInsights","text":"evalResult subset evaluation summary. must include columns relevant input type (auxData, metric, method) result values. input_type string specifies input type generating correlation plot. must either \"auxData\", \"metric\", \"method\".","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/benchmarkInsights.html","id":"returns-4","dir":"Reference","previous_headings":"","what":"Returns","title":"A benchmarkInsights object — benchmarkInsights","text":"ggplot2 correlation plot object. plot visualizes correlation matrix using ggcorrplot aesthetic enhancements like labeled values angled axis text.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/benchmarkInsights.html","id":"method-getforestplot-","dir":"Reference","previous_headings":"","what":"Method getForestplot()","title":"A benchmarkInsights object — benchmarkInsights","text":"function generates forest plot using linear models based comparison groups provided evaluation summary. plot created using dotwhisker broom packages, custom grouping labeling.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/benchmarkInsights.html","id":"usage-8","dir":"Reference","previous_headings":"","what":"Usage","title":"A benchmarkInsights object — benchmarkInsights","text":"","code":"benchmarkInsights$getForestplot(evalResult, input_group, input_model)"},{"path":"https://sydneybiox.github.io/BenchHub/reference/benchmarkInsights.html","id":"arguments-8","dir":"Reference","previous_headings":"","what":"Arguments","title":"A benchmarkInsights object — benchmarkInsights","text":"evalResult data frame containing evaluation summary. input_group string specifying grouping variable (\"datasetID\", \"method\", \"auxData\" allowed). input_model string specifying model variable (\"datasetID\", \"method\",  \"auxData\" allowed).","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/benchmarkInsights.html","id":"returns-5","dir":"Reference","previous_headings":"","what":"Returns","title":"A benchmarkInsights object — benchmarkInsights","text":"forest plot showing comparison models across groups.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/benchmarkInsights.html","id":"method-clone-","dir":"Reference","previous_headings":"","what":"Method clone()","title":"A benchmarkInsights object — benchmarkInsights","text":"objects class cloneable method.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/benchmarkInsights.html","id":"usage-9","dir":"Reference","previous_headings":"","what":"Usage","title":"A benchmarkInsights object — benchmarkInsights","text":"","code":"benchmarkInsights$clone(deep = FALSE)"},{"path":"https://sydneybiox.github.io/BenchHub/reference/benchmarkInsights.html","id":"arguments-9","dir":"Reference","previous_headings":"","what":"Arguments","title":"A benchmarkInsights object — benchmarkInsights","text":"deep Whether make deep clone.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/benchmarkInsights.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"A benchmarkInsights object — benchmarkInsights","text":"","code":"benchmarkInsights$new() #> <benchmarkInsights> #>   Public: #>     addMetadata: function (metadata)  #>     addevalSummary: function (additional_evalResult)  #>     clone: function (deep = FALSE)  #>     evalSummary: data.frame #>     getBoxplot: function (evalResult, metricVariable, auxDataVariable)  #>     getCorplot: function (evalResult, input_type)  #>     getForestplot: function (evalResult, input_group, input_model)  #>     getHeatmap: function (evalSummary)  #>     getLineplot: function (evalResult, order = NULL, metricVariable)  #>     getScatterplot: function (evalResult, variables)  #>     initialize: function (evalResult = NULL)  #>     metadata: NULL"},{"path":"https://sydneybiox.github.io/BenchHub/reference/brierScoreMetric.html","id":null,"dir":"Reference","previous_headings":"","what":"Brier Score Metric — brierScoreMetric","title":"Brier Score Metric — brierScoreMetric","text":"Computes Brier score survival analysis.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/brierScoreMetric.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Brier Score Metric — brierScoreMetric","text":"","code":"brierScoreMetric(auxData, predicted)"},{"path":"https://sydneybiox.github.io/BenchHub/reference/brierScoreMetric.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Brier Score Metric — brierScoreMetric","text":"auxData true survival times event indicators. predicted predicted survival times.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/brierScoreMetric.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Brier Score Metric — brierScoreMetric","text":"Brier score.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/brierScoreMetric.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Brier Score Metric — brierScoreMetric","text":"","code":"# More realistic training dataset (8 patients) auxData <- list(   survival::Surv(time = c(5, 10, 15, 20, 25, 30, 35, 40),    event = c(1, 1, 0, 1, 0, 1, 1, 0)),  # Training   survival::Surv(time = c(12, 18, 25, 32),   event = c(1, 0, 1, 0))  # Testing ) # Predicted risk scores predicted <- list(   c(0.5142118, 0.3902035, 0.9057381, 0.4469696,    0.8360043, 0.7375956, 0.8110551, 0.3881083),  # Training predictions   c(0.685169729, 0.003948339, 0.832916080, 0.007334147)  # Testing predictions ) brierScoreMetric(auxData, predicted) #> [1] 0.01057958 0.04156804 0.17674010 0.16438778 0.24591007 0.15448003 0.03400678 #> [8] 0.03400678"},{"path":"https://sydneybiox.github.io/BenchHub/reference/dot-positivesNegatives.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute Positives and Negatives — .positivesNegatives","title":"Compute Positives and Negatives — .positivesNegatives","text":"Computes true positives, false positives, false negatives, true negatives.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/dot-positivesNegatives.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute Positives and Negatives — .positivesNegatives","text":"","code":".positivesNegatives(auxData, predicted)"},{"path":"https://sydneybiox.github.io/BenchHub/reference/dot-positivesNegatives.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute Positives and Negatives — .positivesNegatives","text":"auxData true labels. predicted predicted labels.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/dot-positivesNegatives.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute Positives and Negatives — .positivesNegatives","text":"list containing true positives, false positives, false negatives, true negatives.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/dot-positivesNegatives.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute Positives and Negatives — .positivesNegatives","text":"","code":"auxData <- factor(c(\"A\", \"B\", \"A\", \"B\")) predicted <- factor(c(\"A\", \"A\", \"A\", \"B\")) .positivesNegatives(auxData, predicted) #> $TP #> A B  #> 2 1  #>  #> $FP #> A B  #> 1 0  #>  #> $FN #> A B  #> 0 1  #>  #> $TN #> A B  #> 1 2  #>"},{"path":"https://sydneybiox.github.io/BenchHub/reference/experimenthubDl.html","id":null,"dir":"Reference","previous_headings":"","what":"Download files from ExperimentHub — experimenthubDl","title":"Download files from ExperimentHub — experimenthubDl","text":"Get dataset ExperimentHub","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/experimenthubDl.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download files from ExperimentHub — experimenthubDl","text":"","code":"experimenthubDl(ID, cachePath)"},{"path":"https://sydneybiox.github.io/BenchHub/reference/experimenthubDl.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download files from ExperimentHub — experimenthubDl","text":"ID ID, string, \"EH\" followed series numbers (e.g. EH119) cachePath path store downloaded file.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/experimenthubDl.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Download files from ExperimentHub — experimenthubDl","text":"path downloaded file.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/figshareDl.html","id":null,"dir":"Reference","previous_headings":"","what":"Download files from geo — figshareDl","title":"Download files from geo — figshareDl","text":"Download main supplimentary files GEO.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/figshareDl.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download files from geo — figshareDl","text":"","code":"figshareDl(ID, cachePath)"},{"path":"https://sydneybiox.github.io/BenchHub/reference/figshareDl.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download files from geo — figshareDl","text":"ID ID, formatted either \"ARTICLE_ID\" main file \"ARTICLE_ID/FILE_ID\" specific file. cachePath path store downloaded file.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/figshareDl.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Download files from geo — figshareDl","text":"path downloaded file.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/geoDl.html","id":null,"dir":"Reference","previous_headings":"","what":"Download files from geo — geoDl","title":"Download files from geo — geoDl","text":"Download main supplementary files GEO.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/geoDl.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download files from geo — geoDl","text":"","code":"geoDl(ID, cachePath)"},{"path":"https://sydneybiox.github.io/BenchHub/reference/geoDl.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download files from geo — geoDl","text":"ID ID, formatted either \"GSEXXXXXX\" main file \"GSEXXXXXX/SupFile.tar.gz\" supplementary file. cachePath path store downloaded file.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/geoDl.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Download files from geo — geoDl","text":"path downloaded file.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/ghCIndexMetric.html","id":null,"dir":"Reference","previous_headings":"","what":"GH C-Index Metric — ghCIndexMetric","title":"GH C-Index Metric — ghCIndexMetric","text":"Computes GH C-Index survival analysis.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/ghCIndexMetric.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"GH C-Index Metric — ghCIndexMetric","text":"","code":"ghCIndexMetric(auxData, predicted)"},{"path":"https://sydneybiox.github.io/BenchHub/reference/ghCIndexMetric.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"GH C-Index Metric — ghCIndexMetric","text":"auxData true survival times event indicators. predicted predicted survival times.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/ghCIndexMetric.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"GH C-Index Metric — ghCIndexMetric","text":"GH C-Index.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/ghCIndexMetric.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"GH C-Index Metric — ghCIndexMetric","text":"","code":"# More realistic training dataset (8 patients) auxData <- list(   survival::Surv(time = c(5, 10, 15, 20, 25, 30, 35, 40),    event = c(1, 1, 0, 1, 0, 1, 1, 0)),  # Training   survival::Surv(time = c(12, 18, 25, 32),    event = c(1, 0, 1, 0))  # Testing ) # Predicted risk scores predicted <- list(   c(0.5142118, 0.3902035, 0.9057381, 0.4469696,    0.8360043, 0.7375956, 0.8110551, 0.3881083),  # Training predictions   c(0.685169729, 0.003948339, 0.832916080, 0.007334147)  # Testing predictions ) ghCIndexMetric(auxData, predicted) #> [1] 0.6260899"},{"path":"https://sydneybiox.github.io/BenchHub/reference/harrelCIndexMetric.html","id":null,"dir":"Reference","previous_headings":"","what":"Harrel's C-Index Metric — harrelCIndexMetric","title":"Harrel's C-Index Metric — harrelCIndexMetric","text":"Computes Harrel's C-Index survival analysis.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/harrelCIndexMetric.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Harrel's C-Index Metric — harrelCIndexMetric","text":"","code":"harrelCIndexMetric(auxData, predicted)"},{"path":"https://sydneybiox.github.io/BenchHub/reference/harrelCIndexMetric.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Harrel's C-Index Metric — harrelCIndexMetric","text":"auxData true survival times event indicators. predicted predicted survival times.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/harrelCIndexMetric.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Harrel's C-Index Metric — harrelCIndexMetric","text":"Harrel's C-Index.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/harrelCIndexMetric.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Harrel's C-Index Metric — harrelCIndexMetric","text":"","code":"# More realistic training dataset (8 patients) auxData <- list(   survival::Surv(time = c(5, 10, 15, 20, 25, 30, 35, 40),    event = c(1, 1, 0, 1, 0, 1, 1, 0)),  # Training   survival::Surv(time = c(12, 18, 25, 32),   event = c(1, 0, 1, 0))  # Testing ) # Predicted risk scores predicted <- list(   c(0.5142118, 0.3902035, 0.9057381, 0.4469696,    0.8360043, 0.7375956, 0.8110551, 0.3881083),  # Training predictions   c(0.685169729, 0.003948339, 0.832916080, 0.007334147)  # Testing predictions ) harrelCIndexMetric(auxData, predicted) #> C Index  #>    0.75"},{"path":"https://sydneybiox.github.io/BenchHub/reference/kdeMetric.html","id":null,"dir":"Reference","previous_headings":"","what":"Kernel Density Estimation (KDE) Metric — kdeMetric","title":"Kernel Density Estimation (KDE) Metric — kdeMetric","text":"Computes kernel density estimation test statistic.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/kdeMetric.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Kernel Density Estimation (KDE) Metric — kdeMetric","text":"","code":"kdeMetric(auxData, predicted)"},{"path":"https://sydneybiox.github.io/BenchHub/reference/kdeMetric.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Kernel Density Estimation (KDE) Metric — kdeMetric","text":"auxData true values. predicted predicted values.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/kdeMetric.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Kernel Density Estimation (KDE) Metric — kdeMetric","text":"KDE test statistic.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/kdeMetric.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Kernel Density Estimation (KDE) Metric — kdeMetric","text":"","code":"auxData <- c(1, 2, 3, 4) predicted <- c(1.1, 2.1, 2.9, 4.2) kdeMetric(auxData, predicted) #> [1] -9.594744"},{"path":"https://sydneybiox.github.io/BenchHub/reference/lubomski_microbiome_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Human Gut Microbiome Abundance and Patient Classes — lubomski_microbiome_data","title":"Human Gut Microbiome Abundance and Patient Classes — lubomski_microbiome_data","text":"Data set consists matrix abundances 1192 microbial taxa 575 samples factor vector classes Parkinson's disease 575 patients","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/lubomski_microbiome_data.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Human Gut Microbiome Abundance and Patient Classes — lubomski_microbiome_data","text":"x row sample column taxon. lubomPD factor vector values 0 representing Healthy Control (HC) 1 representing Parkinson's Disease (PD).","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/lubomski_microbiome_data.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Human Gut Microbiome Abundance and Patient Classes — lubomski_microbiome_data","text":"R package PD16Sdata, BMC, 2023. Webpage: https://microbiomejournal.biomedcentral.com/articles/10.1186/s40168-023-01475-4","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/macroF1Metric.html","id":null,"dir":"Reference","previous_headings":"","what":"Macro F1 Score Metric — macroF1Metric","title":"Macro F1 Score Metric — macroF1Metric","text":"Computes macro F1 score predictions.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/macroF1Metric.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Macro F1 Score Metric — macroF1Metric","text":"","code":"macroF1Metric(auxData, predicted)"},{"path":"https://sydneybiox.github.io/BenchHub/reference/macroF1Metric.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Macro F1 Score Metric — macroF1Metric","text":"auxData true labels. predicted predicted labels.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/macroF1Metric.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Macro F1 Score Metric — macroF1Metric","text":"macro F1 score.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/macroF1Metric.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Macro F1 Score Metric — macroF1Metric","text":"","code":"auxData <- factor(c(\"A\", \"B\", \"A\", \"B\")) predicted <- factor(c(\"A\", \"A\", \"A\", \"B\")) macroF1Metric(auxData, predicted) #> [1] 0.7894737"},{"path":"https://sydneybiox.github.io/BenchHub/reference/macroPrecMetric.html","id":null,"dir":"Reference","previous_headings":"","what":"Macro Precision Metric — macroPrecMetric","title":"Macro Precision Metric — macroPrecMetric","text":"Computes macro precision predictions.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/macroPrecMetric.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Macro Precision Metric — macroPrecMetric","text":"","code":"macroPrecMetric(auxData, predicted)"},{"path":"https://sydneybiox.github.io/BenchHub/reference/macroPrecMetric.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Macro Precision Metric — macroPrecMetric","text":"auxData true labels. predicted predicted labels.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/macroPrecMetric.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Macro Precision Metric — macroPrecMetric","text":"macro precision.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/macroPrecMetric.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Macro Precision Metric — macroPrecMetric","text":"","code":"auxData <- factor(c(\"A\", \"B\", \"A\", \"B\")) predicted <- factor(c(\"A\", \"A\", \"A\", \"B\")) macroPrecMetric(auxData, predicted) #> [1] 0.8333333"},{"path":"https://sydneybiox.github.io/BenchHub/reference/macroRecMetric.html","id":null,"dir":"Reference","previous_headings":"","what":"Macro Recall Metric — macroRecMetric","title":"Macro Recall Metric — macroRecMetric","text":"Computes macro recall predictions.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/macroRecMetric.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Macro Recall Metric — macroRecMetric","text":"","code":"macroRecMetric(auxData, predicted)"},{"path":"https://sydneybiox.github.io/BenchHub/reference/macroRecMetric.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Macro Recall Metric — macroRecMetric","text":"auxData true labels. predicted predicted labels.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/macroRecMetric.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Macro Recall Metric — macroRecMetric","text":"macro recall.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/macroRecMetric.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Macro Recall Metric — macroRecMetric","text":"","code":"auxData <- factor(c(\"A\", \"B\", \"A\", \"B\")) predicted <- factor(c(\"A\", \"A\", \"A\", \"B\")) macroRecMetric(auxData, predicted) #> [1] 0.75"},{"path":"https://sydneybiox.github.io/BenchHub/reference/microF1Metric.html","id":null,"dir":"Reference","previous_headings":"","what":"Micro F1 Score Metric — microF1Metric","title":"Micro F1 Score Metric — microF1Metric","text":"Computes micro F1 score predictions.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/microF1Metric.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Micro F1 Score Metric — microF1Metric","text":"","code":"microF1Metric(auxData, predicted)"},{"path":"https://sydneybiox.github.io/BenchHub/reference/microF1Metric.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Micro F1 Score Metric — microF1Metric","text":"auxData true labels. predicted predicted labels.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/microF1Metric.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Micro F1 Score Metric — microF1Metric","text":"micro F1 score.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/microF1Metric.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Micro F1 Score Metric — microF1Metric","text":"","code":"auxData <- factor(c(\"A\", \"B\", \"A\", \"B\")) predicted <- factor(c(\"A\", \"A\", \"A\", \"B\")) microF1Metric(auxData, predicted) #> [1] 0.75"},{"path":"https://sydneybiox.github.io/BenchHub/reference/microPrecMetric.html","id":null,"dir":"Reference","previous_headings":"","what":"Micro Precision Metric — microPrecMetric","title":"Micro Precision Metric — microPrecMetric","text":"Computes micro precision predictions.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/microPrecMetric.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Micro Precision Metric — microPrecMetric","text":"","code":"microPrecMetric(auxData, predicted)"},{"path":"https://sydneybiox.github.io/BenchHub/reference/microPrecMetric.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Micro Precision Metric — microPrecMetric","text":"auxData true labels. predicted predicted labels.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/microPrecMetric.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Micro Precision Metric — microPrecMetric","text":"micro precision.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/microPrecMetric.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Micro Precision Metric — microPrecMetric","text":"","code":"auxData <- factor(c(\"A\", \"B\", \"A\", \"B\")) predicted <- factor(c(\"A\", \"A\", \"A\", \"B\")) microPrecMetric(auxData, predicted) #> [1] 0.75"},{"path":"https://sydneybiox.github.io/BenchHub/reference/microRecMetric.html","id":null,"dir":"Reference","previous_headings":"","what":"Micro Recall Metric — microRecMetric","title":"Micro Recall Metric — microRecMetric","text":"Computes micro recall predictions.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/microRecMetric.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Micro Recall Metric — microRecMetric","text":"","code":"microRecMetric(auxData, predicted)"},{"path":"https://sydneybiox.github.io/BenchHub/reference/microRecMetric.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Micro Recall Metric — microRecMetric","text":"auxData true labels. predicted predicted labels.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/microRecMetric.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Micro Recall Metric — microRecMetric","text":"micro recall.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/microRecMetric.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Micro Recall Metric — microRecMetric","text":"","code":"auxData <- factor(c(\"A\", \"B\", \"A\", \"B\")) predicted <- factor(c(\"A\", \"A\", \"A\", \"B\")) microRecMetric(auxData, predicted) #> [1] 0.75"},{"path":"https://sydneybiox.github.io/BenchHub/reference/timeDependentAUCMetric.html","id":null,"dir":"Reference","previous_headings":"","what":"Time-Dependent AUC Metric — timeDependentAUCMetric","title":"Time-Dependent AUC Metric — timeDependentAUCMetric","text":"Computes time-dependent AUC survival analysis.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/timeDependentAUCMetric.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Time-Dependent AUC Metric — timeDependentAUCMetric","text":"","code":"timeDependentAUCMetric(auxData, predicted)"},{"path":"https://sydneybiox.github.io/BenchHub/reference/timeDependentAUCMetric.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Time-Dependent AUC Metric — timeDependentAUCMetric","text":"auxData true survival times event indicators. predicted predicted survival times.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/timeDependentAUCMetric.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Time-Dependent AUC Metric — timeDependentAUCMetric","text":"time-dependent AUC.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/timeDependentAUCMetric.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Time-Dependent AUC Metric — timeDependentAUCMetric","text":"","code":"# More realistic training dataset (8 patients) auxData <- list(   survival::Surv(time = c(5, 10, 15, 20, 25, 30, 35, 40),    event = c(1, 1, 0, 1, 0, 1, 1, 0)),  # Training   survival::Surv(time = c(12, 18, 25, 32),   event = c(1, 0, 1, 0))  # Testing )  # Predicted risk scores predicted <- list(   c(0.5142118, 0.3902035, 0.9057381, 0.4469696,    0.8360043, 0.7375956, 0.8110551, 0.3881083),  # Training predictions   c(0.685169729, 0.003948339, 0.832916080, 0.007334147)  # Testing predictions ) timeDependentAUCMetric(auxData, predicted) #> [1] 0.1250000 0.1250000 0.6666667 0.5000000 1.0000000 1.0000000 0.0000000 #> [8] 0.0000000"},{"path":"https://sydneybiox.github.io/BenchHub/reference/unoCIndexMetric.html","id":null,"dir":"Reference","previous_headings":"","what":"Uno's C-Index Metric — unoCIndexMetric","title":"Uno's C-Index Metric — unoCIndexMetric","text":"Computes Uno's C-Index survival analysis.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/unoCIndexMetric.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Uno's C-Index Metric — unoCIndexMetric","text":"","code":"unoCIndexMetric(auxData, predicted)"},{"path":"https://sydneybiox.github.io/BenchHub/reference/unoCIndexMetric.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Uno's C-Index Metric — unoCIndexMetric","text":"auxData true survival times event indicators. predicted predicted survival times.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/unoCIndexMetric.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Uno's C-Index Metric — unoCIndexMetric","text":"Uno's C-Index.","code":""},{"path":"https://sydneybiox.github.io/BenchHub/reference/unoCIndexMetric.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Uno's C-Index Metric — unoCIndexMetric","text":"","code":"# More realistic training dataset (8 patients) auxData <- list(   survival::Surv(time = c(5, 10, 15, 20, 25, 30, 35, 40),    event = c(1, 1, 0, 1, 0, 1, 1, 0)),  # Training   survival::Surv(time = c(12, 18, 25, 32),   event = c(1, 0, 1, 0))  # Testing ) # Predicted risk scores predicted <- list(   c(0.5142118, 0.3902035, 0.9057381, 0.4469696,    0.8360043, 0.7375956, 0.8110551, 0.3881083),  # Training predictions   c(0.685169729, 0.003948339, 0.832916080, 0.007334147)  # Testing predictions ) unoCIndexMetric(auxData, predicted) #> [1] 0.8095238"}]
