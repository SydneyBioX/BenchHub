<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Introduction of benchmarkInsight class • BenchHub</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Introduction of benchmarkInsight class">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-dark" data-bs-theme="dark" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">BenchHub</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.0.1</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="active nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles">
<li><a class="dropdown-item" href="../articles/v01_intro_trio.html">1 Introduction to the Trio Class</a></li>
    <li><a class="dropdown-item" href="../articles/v02_Evaluation_using_Trio.html">2 Evaluation using TrioR</a></li>
    <li><a class="dropdown-item" href="../articles/v03_intro_bmi.html">Introduction of benchmarkInsight class</a></li>
  </ul>
</li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json">
</form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/SydneyBioX/BenchHub/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>Introduction of benchmarkInsight class</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/SydneyBioX/BenchHub/blob/main/vignettes/v03_intro_bmi.Rmd" class="external-link"><code>vignettes/v03_intro_bmi.Rmd</code></a></small>
      <div class="d-none name"><code>v03_intro_bmi.Rmd</code></div>
    </div>

    
    
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># devtools::load_all()</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://sydneybiox.github.io/BenchHub/">BenchHub</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://readr.tidyverse.org" class="external-link">readr</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://dplyr.tidyverse.org" class="external-link">dplyr</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://stringr.tidyverse.org" class="external-link">stringr</a></span><span class="op">)</span></span></code></pre></div>
<div class="section level2">
<h2 id="motivation">Motivation<a class="anchor" aria-label="anchor" href="#motivation"></a>
</h2>
<p>BenchHub—an R ecosystem to make benchmarking easier. It organizes
evaluation metrics, gold standards(Auxiliary Data), and even provides
built-in visualization tools to help interpret results. With BenchHub,
researchers can quickly compare new methods, gain insights, and actually
trust their benchmarking studies. In this vignette, we are going to
introduce benchmarkInsights class.</p>
</div>
<div class="section level2">
<h2 id="creating-benchmarkinsights-class">Creating benchmarkInsights class<a class="anchor" aria-label="anchor" href="#creating-benchmarkinsights-class"></a>
</h2>
<p><code>benchmarkInsight</code> objects can be created using the
corresponding constructor. For example, if you have a benchmark result
formatted in dataframe, you can create a <code>benchmarkInsight</code>
object as follows. The dataframe includes fixed name columns:
<code>datasetID</code>, method, auxData, metric, result. Here I will use
the benchmark result from SpatialSimBench to create a new object.</p>
<p><code>benchmarkInsight</code> object can be instantiated using their
respective constructors. For example, if you have a benchmark result
stored as a dataframe, you can create a Trio object as follows. The
dataframe must include the following fixed columns:
<code>datasetID</code>, <code>method</code>, <code>auxData</code>,
<code>metric</code>, and <code>result</code>. Here, I demonstrate this
using benchmark results from SpatialSimBench to initialize a new
object.</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">result_path</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/system.file.html" class="external-link">system.file</a></span><span class="op">(</span><span class="st">"extdata"</span>, <span class="st">"spatialsimbench_result.csv"</span>, package <span class="op">=</span> <span class="st">"BenchHub"</span><span class="op">)</span></span>
<span><span class="va">spatialsimbench_result</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://readr.tidyverse.org/reference/read_delim.html" class="external-link">read_csv</a></span><span class="op">(</span><span class="va">result_path</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://pillar.r-lib.org/reference/glimpse.html" class="external-link">glimpse</a></span><span class="op">(</span><span class="va">spatialsimbench_result</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## Rows: 3,861</span></span>
<span><span class="co">## Columns: 5</span></span>
<span><span class="co">## $ datasetID <span style="color: #949494; font-style: italic;">&lt;chr&gt;</span> "BREAST", "HOSTEOSARCOMA", "HPROSTATE", "MBRAIN", "MCATUMOR"…</span></span>
<span><span class="co">## $ method    <span style="color: #949494; font-style: italic;">&lt;chr&gt;</span> "scDesign2", "scDesign2", "scDesign2", "scDesign2", "scDesig…</span></span>
<span><span class="co">## $ auxData   <span style="color: #949494; font-style: italic;">&lt;chr&gt;</span> "scaledVar", "scaledVar", "scaledVar", "scaledVar", "scaledV…</span></span>
<span><span class="co">## $ metric    <span style="color: #949494; font-style: italic;">&lt;chr&gt;</span> "KDEstat", "KDEstat", "KDEstat", "KDEstat", "KDEstat", "KDEs…</span></span>
<span><span class="co">## $ result    <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span> -0.18447837, 3.33680301, 6.95418978, 0.62077112, 0.34212005,…</span></span></code></pre>
<p>If you use <code>trio$evaluation()</code>, the output will be
automatically formatted as the required dataframe. However, if you use
your own benchmark evaluation results, you ensure they adhere to the
expected format.</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">bmi</span> <span class="op">&lt;-</span> <span class="va"><a href="../reference/benchmarkInsights.html">benchmarkInsights</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span><span class="va">spatialsimbench_result</span><span class="op">)</span></span>
<span><span class="va">bmi</span></span></code></pre></div>
<pre><code><span><span class="co">## &lt;benchmarkInsights&gt;</span></span>
<span><span class="co">##   Public:</span></span>
<span><span class="co">##     addevalSummary: function (additional_evalResult) </span></span>
<span><span class="co">##     addMetadata: function (metadata) </span></span>
<span><span class="co">##     clone: function (deep = FALSE) </span></span>
<span><span class="co">##     evalSummary: spec_tbl_df, tbl_df, tbl, data.frame</span></span>
<span><span class="co">##     getBoxplot: function (evalResult, metricVariable, auxDataVariable) </span></span>
<span><span class="co">##     getCorplot: function (evalResult, input_type) </span></span>
<span><span class="co">##     getForestplot: function (evalResult, input_group, input_model) </span></span>
<span><span class="co">##     getHeatmap: function (evalSummary) </span></span>
<span><span class="co">##     getLineplot: function (evalResult, order = NULL, metricVariable) </span></span>
<span><span class="co">##     getScatterplot: function (evalResult, variables) </span></span>
<span><span class="co">##     initialize: function (evalResult = NULL) </span></span>
<span><span class="co">##     metadata: NULL</span></span></code></pre>
<p>If you have additional evaluation result, you can use
<code>addevalSummary()</code>. Here is the example:</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">add_result</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html" class="external-link">data.frame</a></span><span class="op">(</span></span>
<span>  datasetID <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="st">"BREAST"</span>, <span class="fl">13</span><span class="op">)</span>,</span>
<span>  method <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"scDesign2"</span>, <span class="st">"scDesign3_gau"</span>, <span class="st">"scDesign3_nb"</span>, <span class="st">"scDesign3_poi"</span>, </span>
<span>             <span class="st">"SPARsim"</span>, <span class="st">"splatter"</span>, <span class="st">"SRTsim"</span>, <span class="st">"symsim"</span>, <span class="st">"zinbwave"</span>, </span>
<span>             <span class="st">"scDesign3_gau(rf)"</span>, <span class="st">"scDesign3_nb(rf)"</span>, <span class="st">"scDesign3_poi(rf)"</span>, <span class="st">"SRTsim(rf)"</span><span class="op">)</span>,</span>
<span>  auxData <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="st">"svg"</span>, <span class="fl">13</span><span class="op">)</span>,</span>
<span>  metric <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="st">"recall"</span>, <span class="fl">13</span><span class="op">)</span>,</span>
<span>  result <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0.921940928</span>, <span class="fl">0.957805907</span>, <span class="fl">0.964135021</span>, <span class="fl">0.989451477</span>, <span class="fl">0.774261603</span>, </span>
<span>             <span class="fl">0.890295359</span>, <span class="fl">0.985232068</span>, <span class="fl">0.067510549</span>, <span class="fl">0.888185654</span>, </span>
<span>             <span class="fl">0.957805907</span>, <span class="fl">0.964135021</span>, <span class="fl">0.989451477</span>, <span class="fl">0.985232068</span><span class="op">)</span>,</span>
<span>  stringsAsFactors <span class="op">=</span> <span class="cn">FALSE</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="va">bmi</span><span class="op">$</span><span class="fu">addevalSummary</span><span class="op">(</span><span class="va">add_result</span><span class="op">)</span></span></code></pre></div>
<p>If you add additional metadata of method, you can use
<code>addMetadata()</code>. Here is the example:</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">metadata_srtsim</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html" class="external-link">data.frame</a></span><span class="op">(</span></span>
<span>  method <span class="op">=</span> <span class="st">"SRTsim"</span>,</span>
<span>  year <span class="op">=</span> <span class="fl">2023</span>,</span>
<span>  packageVersion <span class="op">=</span> <span class="st">"0.99.6"</span>,</span>
<span>  parameterSetting <span class="op">=</span> <span class="st">"default"</span>,</span>
<span>  spatialInfoReq <span class="op">=</span> <span class="st">"No"</span>,</span>
<span>  DOI <span class="op">=</span> <span class="st">"10.1186/s13059-023-02879-z"</span>,</span>
<span>  stringsAsFactors <span class="op">=</span> <span class="cn">FALSE</span></span>
<span>  <span class="op">)</span></span>
<span></span>
<span><span class="va">bmi</span><span class="op">$</span><span class="fu">addMetadata</span><span class="op">(</span><span class="va">metadata_srtsim</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="visualization">Visualization<a class="anchor" aria-label="anchor" href="#visualization"></a>
</h2>
<div class="section level3">
<h3 id="available-plot">Available plot<a class="anchor" aria-label="anchor" href="#available-plot"></a>
</h3>
<p><code>getHeatmap(evalReuslt)</code>: Creates a heatmap from the
evaluation summary by averaging results across datasets.</p>
<ul>
<li>evalResult: A dataframe containing the evaluation summary.</li>
<li>Note: In this heatmap, it averages results across datasets.</li>
</ul>
<p><code>getCorplot(evalReuslt, input_type)</code>: Creates a
correlation plot based on the provided evaluation summary.</p>
<ul>
<li>evalResult: A dataframe containing the evaluation summary.</li>
<li>input_type: either “auxData”, “metric”, or “method”.</li>
</ul>
<p><code>getBoxplot(evalReuslt)</code>: Creates a boxplot based on the
provided evaluation summary.</p>
<ul>
<li>evalReuslt: A dataframe containing the evaluation summary.</li>
<li>input_type: either “auxData”, “metric”, or “method”.</li>
</ul>
<p><code>getForestplot(evalReuslt, input_group, input_model)</code>:
Create a forest plot using linear models based on the comparison between
groups in the provided evaluation summary.</p>
<ul>
<li>evalReuslt: A dataframe containing the evaluation summary.</li>
<li>input_group: A string specifying the grouping variable (only
“datasetID”, “method”, or “auxData” allowed).</li>
<li>input_model: A string specifying the model variable (only
“datasetID”, “method”, or “auxData” allowed).</li>
</ul>
<p><code>getScatterplot(evalReuslt, variables)</code>: a scatter plot
for the same auxData, with an two methodd metrics.</p>
<ul>
<li>evalReuslt: A dataframe containing the evaluation summary, only
include two different metrics, all auxData should be same</li>
<li>variables: A character vector of length two specifying the metric
names to be used for the x and y axes.</li>
</ul>
<p><code>getLineplot(evalReuslt, order)</code>: Creates a line plot for
the given x and y variables, with an optional grouping and fixed x
order.</p>
<ul>
<li>evalReuslt: A dataframe containing the evaluation summary.</li>
<li>order: An optional vector specifying the order of x-axis
values.</li>
</ul>
</div>
<div class="section level3">
<h3 id="interpretation-benchmark-result">Interpretation benchmark result<a class="anchor" aria-label="anchor" href="#interpretation-benchmark-result"></a>
</h3>
<div class="section level4">
<h4 id="case-study-what-is-the-overview-of-summary">Case Study: What is the overview of summary?<a class="anchor" aria-label="anchor" href="#case-study-what-is-the-overview-of-summary"></a>
</h4>
<p>To get a high-level view of method performance, we use a heatmap to
summarize evaluation results across datasets. This helps identify
overall trends, making it easier to compare methods and performance
differences.</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">bmi</span><span class="op">$</span><span class="fu">getHeatmap</span><span class="op">(</span><span class="va">bmi</span><span class="op">$</span><span class="va">evalSummary</span><span class="op">)</span></span></code></pre></div>
<p><img src="v03_intro_bmi_files/figure-html/unnamed-chunk-6-1.png" width="700"></p>
</div>
<div class="section level4">
<h4 id="case-study-what-is-the-correlation-between-auxdatametricmethod">Case Study: What is the correlation between
auxData/metric/method?<a class="anchor" aria-label="anchor" href="#case-study-what-is-the-correlation-between-auxdatametricmethod"></a>
</h4>
<p>To understand the relationships between different evaluation factors,
we use a correlation plot to examine how auxData, metrics, and methods
are interrelated. This helps identify patterns, redundancies, or
dependencies among evaluation components.</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">bmi</span><span class="op">$</span><span class="fu">getCorplot</span><span class="op">(</span><span class="va">bmi</span><span class="op">$</span><span class="va">evalSummary</span>, <span class="st">"method"</span><span class="op">)</span></span></code></pre></div>
<p><img src="v03_intro_bmi_files/figure-html/unnamed-chunk-7-1.png" width="700"></p>
<p>To further investigate the relationship between two specific metrics,
we use a scatter plot. This visualization helps assess how well two
metrics align or diverge across different methods, providing insights
into trade-offs and performance consistency.</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">bmi</span><span class="op">$</span><span class="fu">getScatterplot</span><span class="op">(</span><span class="va">bmi</span><span class="op">$</span><span class="va">evalSummary</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"recall"</span>,<span class="st">"precision"</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p><img src="v03_intro_bmi_files/figure-html/unnamed-chunk-8-1.png" width="700"></p>
</div>
<div class="section level4">
<h4 id="case-study-what-is-the-time-and-memory-trend">Case Study: What is the time and memory trend?<a class="anchor" aria-label="anchor" href="#case-study-what-is-the-time-and-memory-trend"></a>
</h4>
<p>To evaluate the scalability of different methods, we use a line plot
to visualize trends in computational time and memory usage across
different conditions. This helps identify how methods perform as data
complexity increases, revealing potential efficiency trade-offs.</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">bmi</span><span class="op">$</span><span class="fu">getLineplot</span><span class="op">(</span><span class="va">bmi</span><span class="op">$</span><span class="va">evalSummary</span>, metricVariable <span class="op">=</span> <span class="st">"memory"</span><span class="op">)</span></span></code></pre></div>
<p><img src="v03_intro_bmi_files/figure-html/unnamed-chunk-9-1.png" width="700"></p>
</div>
<div class="section level4">
<h4 id="case-study-which-metric-is-most-effective-on-the-method">Case Study: Which metric is most effective on the method?<a class="anchor" aria-label="anchor" href="#case-study-which-metric-is-most-effective-on-the-method"></a>
</h4>
<p>To assess which metrics have the strongest influence on method
performance, we use a forest plot to visualize the relationship between
metrics and methods. This allows us to quantify and compare the impact
of different metrics, helping to identify the most critical evaluation
factors.</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">bmi</span><span class="op">$</span><span class="fu">getForestplot</span><span class="op">(</span><span class="va">bmi</span><span class="op">$</span><span class="va">evalSummary</span>, <span class="st">"metric"</span>, <span class="st">"method"</span><span class="op">)</span></span></code></pre></div>
<p><img src="v03_intro_bmi_files/figure-html/unnamed-chunk-10-1.png" width="700"></p>
</div>
<div class="section level4">
<h4 id="case-study-how-does-method-variability-differ-across-datasets-for-a-specific-metric">Case Study: How does method variability differ across datasets for a
specific metric?<a class="anchor" aria-label="anchor" href="#case-study-how-does-method-variability-differ-across-datasets-for-a-specific-metric"></a>
</h4>
<p>To examine the consistency of each method across different datasets
for a given metric, we use a boxplot. This visualization helps assess
the variability of method performance, highlighting robustness or
instability when applied to different datasets.</p>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">bmi</span><span class="op">$</span><span class="fu">getBoxplot</span><span class="op">(</span><span class="va">bmi</span><span class="op">$</span><span class="va">evalSummary</span>, metricVariable <span class="op">=</span> <span class="st">"KDEstat"</span>, auxDataVariable <span class="op">=</span> <span class="st">"scaledVar"</span><span class="op">)</span></span></code></pre></div>
<p><img src="v03_intro_bmi_files/figure-html/unnamed-chunk-11-1.png" width="700"></p>
</div>
</div>
<div class="section level3">
<h3 id="cheatsheet">Cheatsheet<a class="anchor" aria-label="anchor" href="#cheatsheet"></a>
</h3>
<table class="table">
<colgroup>
<col width="34%">
<col width="65%">
</colgroup>
<thead><tr class="header">
<th align="center">Question</th>
<th align="left">Code</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="center">Summary Overview</td>
<td align="left"><code>getHeatmap(evalReuslt)</code></td>
</tr>
<tr class="even">
<td align="center">Correlation Analysis</td>
<td align="left"><code>getCorplot(evalReuslt, input_type)</code></td>
</tr>
<tr class="odd">
<td align="center">Scalability Trend (Time/ Memory)</td>
<td align="left"><code>getLineplot(evalReuslt, order)</code></td>
</tr>
<tr class="even">
<td align="center">Metric-Model Impact (Modeling)</td>
<td align="left"><code>getForestplot(evalReuslt, input_group, input_model)</code></td>
</tr>
<tr class="odd">
<td align="center">Method Variability Across Datasets</td>
<td align="left"><code>getBoxplot(evalReuslt)</code></td>
</tr>
<tr class="even">
<td align="center">Metric Relationship</td>
<td align="left"><code>getScatterplot(evalReuslt, variables)</code></td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="section level2">
<h2 id="session-info">Session Info<a class="anchor" aria-label="anchor" href="#session-info"></a>
</h2>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/sessionInfo.html" class="external-link">sessionInfo</a></span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## R version 4.4.3 (2025-02-28)</span></span>
<span><span class="co">## Platform: x86_64-pc-linux-gnu</span></span>
<span><span class="co">## Running under: Ubuntu 24.04.2 LTS</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Matrix products: default</span></span>
<span><span class="co">## BLAS:   /usr/lib/x86_64-linux-gnu/openblas-pthread/libblas.so.3 </span></span>
<span><span class="co">## LAPACK: /usr/lib/x86_64-linux-gnu/openblas-pthread/libopenblasp-r0.3.26.so;  LAPACK version 3.12.0</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## locale:</span></span>
<span><span class="co">##  [1] LC_CTYPE=C.UTF-8       LC_NUMERIC=C           LC_TIME=C.UTF-8       </span></span>
<span><span class="co">##  [4] LC_COLLATE=C.UTF-8     LC_MONETARY=C.UTF-8    LC_MESSAGES=C.UTF-8   </span></span>
<span><span class="co">##  [7] LC_PAPER=C.UTF-8       LC_NAME=C              LC_ADDRESS=C          </span></span>
<span><span class="co">## [10] LC_TELEPHONE=C         LC_MEASUREMENT=C.UTF-8 LC_IDENTIFICATION=C   </span></span>
<span><span class="co">## </span></span>
<span><span class="co">## time zone: UTC</span></span>
<span><span class="co">## tzcode source: system (glibc)</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## attached base packages:</span></span>
<span><span class="co">## [1] stats     graphics  grDevices utils     datasets  methods   base     </span></span>
<span><span class="co">## </span></span>
<span><span class="co">## other attached packages:</span></span>
<span><span class="co">## [1] stringr_1.5.1    dplyr_1.1.4      readr_2.1.5      BenchHub_0.0.1  </span></span>
<span><span class="co">## [5] ggplot2_3.5.1    BiocStyle_2.34.0</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## loaded via a namespace (and not attached):</span></span>
<span><span class="co">##   [1] Rdpack_2.6.2        gridExtra_2.3       sandwich_3.1-1     </span></span>
<span><span class="co">##   [4] rlang_1.1.5         magrittr_2.0.3      multcomp_1.4-28    </span></span>
<span><span class="co">##   [7] polspline_1.1.25    compiler_4.4.3      survAUC_1.3-0      </span></span>
<span><span class="co">##  [10] systemfonts_1.2.1   vctrs_0.6.5         reshape2_1.4.4     </span></span>
<span><span class="co">##  [13] quantreg_6.1        crayon_1.5.3        pkgconfig_2.0.3    </span></span>
<span><span class="co">##  [16] fastmap_1.2.0       backports_1.5.0     labeling_0.4.3     </span></span>
<span><span class="co">##  [19] ggstance_0.3.7      rmarkdown_2.29      tzdb_0.4.0         </span></span>
<span><span class="co">##  [22] ragg_1.3.3          bit_4.6.0           MatrixModels_0.5-3 </span></span>
<span><span class="co">##  [25] purrr_1.0.4         xfun_0.51           cachem_1.1.0       </span></span>
<span><span class="co">##  [28] jsonlite_1.9.1      tweenr_2.0.3        parallel_4.4.3     </span></span>
<span><span class="co">##  [31] broom_1.0.7         cluster_2.1.8       R6_2.6.1           </span></span>
<span><span class="co">##  [34] RColorBrewer_1.1-3  bslib_0.9.0         stringi_1.8.4      </span></span>
<span><span class="co">##  [37] rpart_4.1.24        jquerylib_0.1.4     cellranger_1.1.0   </span></span>
<span><span class="co">##  [40] assertthat_0.2.1    Rcpp_1.0.14         bookdown_0.42      </span></span>
<span><span class="co">##  [43] knitr_1.49          zoo_1.8-13          base64enc_0.1-3    </span></span>
<span><span class="co">##  [46] parameters_0.24.2   Matrix_1.7-2        splines_4.4.3      </span></span>
<span><span class="co">##  [49] nnet_7.3-20         tidyselect_1.2.1    rstudioapi_0.17.1  </span></span>
<span><span class="co">##  [52] yaml_2.3.10         codetools_0.2-20    curl_6.2.1         </span></span>
<span><span class="co">##  [55] lattice_0.22-6      tibble_3.2.1        plyr_1.8.9         </span></span>
<span><span class="co">##  [58] withr_3.0.2         bayestestR_0.15.2   evaluate_1.0.3     </span></span>
<span><span class="co">##  [61] foreign_0.8-88      desc_1.4.3          survival_3.8-3     </span></span>
<span><span class="co">##  [64] polyclip_1.10-7     pillar_1.10.1       BiocManager_1.30.25</span></span>
<span><span class="co">##  [67] checkmate_2.3.2     insight_1.1.0       generics_0.1.3     </span></span>
<span><span class="co">##  [70] vroom_1.6.5         hms_1.1.3           munsell_0.5.1      </span></span>
<span><span class="co">##  [73] scales_1.3.0        glue_1.8.0          rms_7.0-0          </span></span>
<span><span class="co">##  [76] Hmisc_5.2-2         tools_4.4.3         data.table_1.17.0  </span></span>
<span><span class="co">##  [79] SparseM_1.84-2      fs_1.6.5            mvtnorm_1.3-3      </span></span>
<span><span class="co">##  [82] cowplot_1.1.3       grid_4.4.3          tidyr_1.3.1        </span></span>
<span><span class="co">##  [85] rbibutils_2.3       datawizard_1.0.1    colorspace_2.1-1   </span></span>
<span><span class="co">##  [88] nlme_3.1-167        googlesheets4_1.1.1 patchwork_1.3.0    </span></span>
<span><span class="co">##  [91] performance_0.13.0  ggforce_0.4.2       htmlTable_2.4.3    </span></span>
<span><span class="co">##  [94] googledrive_2.1.1   splitTools_1.0.1    Formula_1.2-5      </span></span>
<span><span class="co">##  [97] cli_3.6.4           textshaping_1.0.0   gargle_1.5.2       </span></span>
<span><span class="co">## [100] funkyheatmap_0.5.1  gtable_0.3.6        ggcorrplot_0.1.4.1 </span></span>
<span><span class="co">## [103] ggsci_3.2.0         sass_0.4.9          digest_0.6.37      </span></span>
<span><span class="co">## [106] ggrepel_0.9.6       TH.data_1.1-3       htmlwidgets_1.6.4  </span></span>
<span><span class="co">## [109] farver_2.1.2        htmltools_0.5.8.1   pkgdown_2.1.1      </span></span>
<span><span class="co">## [112] lifecycle_1.0.4     bit64_4.6.0-1       dotwhisker_0.8.3   </span></span>
<span><span class="co">## [115] MASS_7.3-64</span></span></code></pre>
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by Cabiria Liang, Sanghyun Kim, Nick Robertson, Marni Torkel, Yue Cao, Dario Strbenac, Jean Yang, SOMS Maintainer.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.1.</p>
</div>

    </footer>
</div>





  </body>
</html>
